{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainframe=pd.read_csv(\"train_data.csv\")\n",
    "train_classes=np.max(trainframe['Label'])\n",
    "images_per_class=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OmniTask():\n",
    "#     def __init__(self,labels,size):\n",
    "#         self.labels=labels\n",
    "#         self.size=size\n",
    "#     def sample_data(self):\n",
    "#         labelframe=trainframe.iloc[(self.label*samples_per_class):((self.label+1)*samples_per_class)]\n",
    "#         labelframe.reset_index(inplace=True,drop=True)\n",
    "#         rand_samples=np.random.choice(samples_per_class,replace=True,size=self.size)\n",
    "#         images=[]\n",
    "#         labels=[]\n",
    "#         for sample in rand_samples:\n",
    "#             img_path=labelframe.iloc[s]['Path']\n",
    "#             img_label=labelframe.iloc[s]['Label']\n",
    "#             img=cv2.imread(img_path)\n",
    "#             images.append(img)\n",
    "#             labels.append(img_label)\n",
    "#         images=torch.stack([torch.tensor(images[i]) for i in range(len(images))])\n",
    "#         images=images.float()\n",
    "#         labels=torch.FloatTensor(labels)\n",
    "#         miniset=torch.utils.data.TensorDataset(images,labels)\n",
    "#         return miniset        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task():\n",
    "    def __init__(self,sample_classes,num_instances):\n",
    "        self.sample_classes=sample_classes\n",
    "        self.num_instances=num_instances\n",
    "    def sample_data(self):\n",
    "    #num_classes=5/20 for 5/20 way classification. num_instances=k for 'k shot' learning\n",
    "    #sample_classes=np.random.choice(train_classes,replace=True,size=num_classes)\n",
    "    #for each of these classes, get num_instances number of samples\n",
    "        label=0\n",
    "        images=[]\n",
    "        labels=[]\n",
    "        for c in self.sample_classes:\n",
    "            cframe=trainframe.iloc[(c*images_per_class):((c+1)*images_per_class)]\n",
    "            cframe.reset_index(inplace=True,drop=True)\n",
    "            sample_idxs=np.random.choice(images_per_class,replace=True,size=self.num_instances)\n",
    "            for s in sample_idxs:\n",
    "                img_path=labelframe.iloc[s]['Path']\n",
    "                img_label=label\n",
    "                img=cv2.imread(img_path,0)\n",
    "                img=cv2.resize(img,dsize=(28,28))\n",
    "                #img=np.array(img)\n",
    "                img=img[...,np.newaxis]\n",
    "                img=np.transpose(img)\n",
    "                images.append(img)\n",
    "                labels.append(img_label)\n",
    "            label+=1\n",
    "        images=torch.stack([torch.tensor(images[i]) for i in range(len(images))])\n",
    "        images=images.float()\n",
    "        labels=torch.Tensor(labels)\n",
    "        labels=labels.long()\n",
    "        miniset=torch.utils.data.TensorDataset(images,labels)\n",
    "        return miniset\n",
    "\n",
    "class TaskDistribution():\n",
    "    def __init__(self,num_classes,num_instances):\n",
    "        self.num_classes=num_classes\n",
    "        self.num_instances=num_instances\n",
    "    def sample_task(self):\n",
    "        sample_classes=np.random.choice(train_classes,replace=True,size=self.num_classes)\n",
    "        return Task(sample_classes,self.num_instances)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "                ('conv1', nn.Conv2d(1, 64, 3)),\n",
    "                ('bn1', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('pool1', nn.MaxPool2d(2,2)),\n",
    "                ('conv2', nn.Conv2d(64,64,3)),\n",
    "                ('bn2', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('pool2', nn.MaxPool2d(2,2)),\n",
    "                ('conv3', nn.Conv2d(64,64,3)),\n",
    "                ('bn3', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "                ('pool3', nn.MaxPool2d(2,2))]))    \n",
    "        self.add_module('fc', nn.Linear(64,num_classes))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.net(x)\n",
    "        x=x.view(-1,64)\n",
    "        x=self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def argforward(self,x,weights):\n",
    "        x = F.conv2d(x, weights['features.conv1.weight'], weights['features.conv1.bias'])\n",
    "        x = F.batch_norm(x, weight = weights['features.bn1.weight'], bias = weights['features.bn1.bias'], momentum=1,\n",
    "                        running_mean = torch.zeros(np.prod(np.array(x.data.size()[1]))).cuda(),\n",
    "                        running_var = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda())\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
    "        x = F.conv2d(x, weights['features.conv2.weight'], weights['features.conv2.bias'])\n",
    "        x = F.batch_norm(x, weight = weights['features.bn2.weight'], bias = weights['features.bn2.bias'], momentum=1,\n",
    "                        running_mean = torch.zeros(np.prod(np.array(x.data.size()[1]))).cuda(),\n",
    "                         running_var = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda())\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
    "        x = F.conv2d(x, weights['features.conv3.weight'], weights['features.conv3.bias'])\n",
    "        x = F.batch_norm(x, weight = weights['features.bn3.weight'], bias = weights['features.bn3.bias'], momentum=1,\n",
    "                        running_mean = torch.zeros(np.prod(np.array(x.data.size()[1]))).cuda(),\n",
    "                         running_var = torch.ones(np.prod(np.array(x.data.size()[1]))).cuda())\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
    "        x = x.view(x.size(0), 64)\n",
    "        x = F.linear(x, weights['fc.weight'], weights['fc.bias'])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(keys,params):\n",
    "    temp=[w.clone() for w in list(params.values())]\n",
    "    l=[]\n",
    "    for s,t in zip(keys,temp):\n",
    "        l.append((s,t))\n",
    "    dic=OrderedDict((s,t) for (s,t) in l)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniMAML(): \n",
    "    def __init__(self,net,alpha,beta,k,num_metatasks,N):\n",
    "        self.net=net\n",
    "        self.alpha=alpha\n",
    "        self.beta=beta\n",
    "        self.k=k #\"k shot\" classification\n",
    "        self.num_metatasks=num_metatasks\n",
    "        self.weights=OrderedDict((name, param) for (name,param) in self.net.named_parameters())\n",
    "        self.criterion=nn.CrossEntropyLoss()\n",
    "        self.optimiser=torch.optim.Adam(list(self.weights.values()),self.beta)\n",
    "        self.meta_losses=[]\n",
    "        self.plot_every=10\n",
    "        self.print_every=500\n",
    "        self.num_metataks=num_metatasks\n",
    "        self.N=N #\"N way\" classification\n",
    "\n",
    "         \n",
    "    def inner_loop(self,task):\n",
    "        temp=[w.clone() for w in list(self.weights.values())]\n",
    "        temp_weights=OrderedDict((name,param) for (name,param) in \n",
    "                                 zip(list(self.weights.keys()),temp))\n",
    "        dset=task.sample_data()\n",
    "        loader=DataLoader(dset,batch_size=self.k*self.N,shuffle=True)\n",
    "        x,y=loader.__iter__().next()\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        output=self.net.argforward(x,temp_weights)\n",
    "        loss=self.criterion(output,y)/(self.k*self.N)\n",
    "        grads=torch.autograd.grad(loss,list(temp_weights.values()))\n",
    "        items=get_weights(keys=list(self.weights.keys()),params=temp_weights)\n",
    "        temp_weights=OrderedDict((name,param-self.alpha*g) for ((name,param),g) in \n",
    "                                 zip(items.items(),grads))\n",
    "        #temp_weights=OrderedDict((name,param-self.alpha*g) for ((name,param),g) in \n",
    "        #                         zip(zip(list(self.weights.keys()),temp)),grads)\n",
    "        z=zip(list(self.weights.keys()),temp)\n",
    "        dset=task.sample_data()\n",
    "        loader=DataLoader(dset,batch_size=self.k*self.N,shuffle=True)\n",
    "        x,y=loader.__iter__().next()\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        output=self.net.argforward(x,temp_weights)\n",
    "        metaloss=self.criterion(output,y)/(self.k*self.N)\n",
    "        return metaloss\n",
    "    \n",
    "    def final_loop(self,num_epochs):\n",
    "        total_loss=0\n",
    "        for epoch in range(1,num_epochs+1):\n",
    "            tasks=TaskDistribution(num_classes=self.N,num_instances=self.k)\n",
    "            metaloss_sum=0\n",
    "            for i in range(self.num_metatasks):\n",
    "                task=tasks.sample_task()\n",
    "                metaloss=self.inner_loop(task)\n",
    "                metaloss_sum+=metaloss\n",
    "            metagrads=torch.autograd.grad(metaloss_sum,list(self.weights.values()))\n",
    "            for w,g in zip(list(self.weights.values()),metagrads):\n",
    "                w.grad=g\n",
    "            self.optimiser.step()\n",
    "            total_loss+=metaloss_sum.item()/self.num_metatasks\n",
    "            if epoch % self.print_every == 0:\n",
    "                print(\"{}/{}. loss: {}\".format(epoch, num_epochs, total_loss / self.plot_every))\n",
    "            if epoch%self.plot_every==0:\n",
    "                self.meta_losses.append(total_loss/self.plot_every)\n",
    "                total_loss = 0\n",
    "            if (epoch%100)==0:\n",
    "                print(\"Epoch \"+str(epoch)+\" completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "net=ConvNet(num_classes=N)\n",
    "net.to(device)\n",
    "maml=OmniMAML(net,alpha=0.1,beta=0.001,k=3,num_metatasks=32,N=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "maml.final_loop(num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('features.conv1.weight', Parameter containing:\n",
       "tensor([[[[ 1.9403e-01, -2.3679e-01,  1.5356e-02],\n",
       "          [ 1.7192e-01, -1.7619e-01, -5.1181e-02],\n",
       "          [ 2.6803e-01,  1.4945e-01, -2.5490e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5718e-01,  2.5654e-01, -6.4612e-02],\n",
       "          [ 1.2119e-01, -1.5504e-01, -2.9659e-01],\n",
       "          [ 1.9620e-02, -1.9034e-01,  9.5991e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 2.3084e-01,  1.7164e-01,  2.7283e-02],\n",
       "          [ 2.6726e-01,  7.3758e-02,  5.6239e-02],\n",
       "          [ 1.4174e-01,  1.0790e-02,  9.6042e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.6255e-01, -3.1555e-01, -1.8513e-01],\n",
       "          [-1.3194e-01, -3.2913e-01,  2.7115e-01],\n",
       "          [-2.6304e-02, -5.0627e-02,  1.5131e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.6226e-01,  2.4513e-02, -2.6430e-01],\n",
       "          [-5.9958e-02,  8.8895e-02,  1.0743e-01],\n",
       "          [-2.3213e-01,  1.1048e-01,  2.3489e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.4756e-03,  1.4024e-01, -2.9164e-01],\n",
       "          [-1.3479e-01, -1.9207e-01, -2.0314e-01],\n",
       "          [-2.7353e-01,  2.6142e-01, -2.3706e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.6504e-01, -2.2353e-01,  1.1712e-01],\n",
       "          [ 1.1956e-01,  2.7649e-01, -2.0259e-01],\n",
       "          [-1.8710e-01,  3.1176e-01,  1.5528e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.9413e-01,  4.8424e-02,  7.3889e-02],\n",
       "          [-2.1505e-01,  1.1044e-01,  7.4240e-03],\n",
       "          [ 2.4389e-01,  2.1123e-02,  2.8800e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.0203e-01,  1.7662e-01,  9.0156e-02],\n",
       "          [ 1.1433e-01,  4.3281e-02, -2.6110e-01],\n",
       "          [-1.8114e-03,  1.6414e-02, -1.4127e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.2693e-01,  2.7209e-01,  3.0499e-01],\n",
       "          [ 3.2873e-01,  2.6905e-01, -1.6718e-01],\n",
       "          [-2.0653e-01, -5.9710e-02,  2.3277e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3998e-02, -2.4578e-01, -6.9340e-02],\n",
       "          [-2.2031e-02, -1.6389e-01, -2.2158e-01],\n",
       "          [ 3.1846e-01,  2.7232e-01, -2.6582e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.9549e-02,  1.9524e-01,  1.5026e-01],\n",
       "          [ 3.0669e-01, -1.3532e-01,  1.3945e-01],\n",
       "          [-5.0661e-02,  2.8519e-01,  2.5853e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.8989e-01, -2.7323e-01, -1.1192e-01],\n",
       "          [-2.3421e-01,  9.5503e-03,  1.4764e-01],\n",
       "          [-3.2046e-01,  1.9271e-01, -7.0710e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.0166e-02, -1.8641e-01,  1.0686e-01],\n",
       "          [-2.2099e-02,  3.0623e-01,  2.7592e-01],\n",
       "          [ 2.5635e-01, -1.7342e-01, -5.6145e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.4874e-01,  2.7465e-01, -3.2786e-01],\n",
       "          [ 2.2477e-01,  1.0441e-01,  2.4889e-01],\n",
       "          [ 3.2103e-01,  2.0313e-01,  1.7142e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.6733e-01,  2.4837e-01, -1.8885e-01],\n",
       "          [-1.9981e-01, -1.5662e-01, -5.3461e-02],\n",
       "          [-2.7634e-01, -3.0709e-01,  2.5937e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1665e-01, -1.6399e-01, -2.6459e-01],\n",
       "          [ 1.6116e-01,  1.7416e-01,  1.7834e-01],\n",
       "          [ 1.9056e-01,  2.8698e-01, -9.8499e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.1810e-01, -4.9093e-02, -2.6480e-01],\n",
       "          [ 2.5131e-01,  6.3317e-02, -2.9737e-01],\n",
       "          [-2.3195e-01,  1.6001e-01, -5.9193e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.8614e-01,  3.2996e-01, -8.0062e-03],\n",
       "          [-2.4581e-01, -2.0412e-01,  2.8860e-01],\n",
       "          [-2.5793e-01, -8.7393e-02,  1.7483e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.7391e-02, -2.7927e-01, -9.2478e-02],\n",
       "          [-9.4458e-02, -2.5115e-01,  9.4550e-02],\n",
       "          [-1.8366e-02, -1.7751e-01, -1.0278e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4758e-01, -2.9636e-02,  8.8756e-02],\n",
       "          [-2.5943e-01,  8.4606e-03, -2.5821e-01],\n",
       "          [-1.7132e-01,  6.2946e-02, -3.0753e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.0381e-01,  1.7786e-01, -3.1917e-01],\n",
       "          [-2.9734e-01,  2.6453e-02,  3.0631e-01],\n",
       "          [ 4.2392e-02,  2.9294e-01, -1.2679e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4424e-01, -2.2995e-01, -1.5987e-01],\n",
       "          [-2.7159e-01,  1.3120e-01, -2.5056e-01],\n",
       "          [-3.1768e-01, -2.5544e-01, -1.1304e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.7021e-02, -3.2938e-01,  3.2461e-01],\n",
       "          [-9.5205e-02,  1.5636e-02, -7.3437e-02],\n",
       "          [ 7.5658e-02,  4.6498e-02, -1.4871e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1671e-01, -2.7321e-01, -2.3820e-01],\n",
       "          [ 1.1419e-01,  1.5681e-01,  2.1927e-01],\n",
       "          [ 2.5088e-01, -2.6716e-01, -1.3429e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.3192e-01, -1.8204e-01, -1.0673e-01],\n",
       "          [ 7.0971e-02, -2.7763e-01, -1.8504e-01],\n",
       "          [ 3.2189e-01,  1.3033e-01,  3.1698e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9771e-01,  2.5434e-02,  7.8876e-02],\n",
       "          [ 1.6489e-01, -5.9994e-02,  1.6280e-01],\n",
       "          [ 2.8181e-01,  2.2979e-01, -1.3474e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.6066e-02,  2.7027e-01,  2.8091e-01],\n",
       "          [ 1.7132e-01, -2.3974e-01, -1.1792e-01],\n",
       "          [ 2.1913e-01,  3.2234e-01,  1.2347e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.5605e-02, -2.0139e-01,  1.3552e-02],\n",
       "          [-1.4517e-01, -8.5627e-02, -1.9015e-01],\n",
       "          [-8.2532e-02,  2.3770e-01,  2.1721e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7520e-01,  1.6083e-01,  1.8358e-01],\n",
       "          [-1.5117e-01, -4.7603e-02,  2.4597e-01],\n",
       "          [ 1.8075e-01,  1.2369e-01,  1.7698e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.5584e-01,  8.7248e-02, -2.7769e-01],\n",
       "          [-2.8667e-01, -1.8832e-01, -2.2002e-01],\n",
       "          [-2.5631e-01,  1.3233e-01,  1.2819e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.9341e-01,  2.1483e-01,  2.0220e-01],\n",
       "          [ 6.7487e-02,  1.3458e-01,  7.0740e-02],\n",
       "          [-1.0161e-01,  3.3311e-01, -3.1730e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.1976e-01, -9.0420e-02,  2.5396e-01],\n",
       "          [-3.2438e-01,  3.2478e-01, -2.5863e-01],\n",
       "          [-2.2571e-01, -3.6290e-02,  3.1173e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.8144e-01, -2.4694e-01,  1.5229e-01],\n",
       "          [ 2.9971e-01,  3.7035e-04, -1.4650e-01],\n",
       "          [-4.0739e-02,  2.0064e-01,  1.7328e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9597e-01, -2.6515e-01, -4.0890e-02],\n",
       "          [-3.1321e-01,  1.2351e-01, -2.4245e-02],\n",
       "          [ 1.0272e-01,  1.5957e-01, -2.5693e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.2003e-01, -2.4574e-01, -1.7039e-01],\n",
       "          [ 2.3889e-01,  2.4357e-01,  1.1597e-01],\n",
       "          [-8.0086e-02, -1.4114e-01,  3.1642e-01]]],\n",
       "\n",
       "\n",
       "        [[[-5.0903e-02, -1.2799e-01, -2.0979e-01],\n",
       "          [ 1.1122e-01,  1.0288e-01,  3.1154e-01],\n",
       "          [ 1.2442e-01,  1.8975e-01, -5.2172e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.1343e-02,  2.9489e-01, -5.5724e-02],\n",
       "          [ 2.7941e-01,  9.7155e-02, -1.4125e-01],\n",
       "          [-1.0445e-02,  2.7509e-01,  1.1658e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5793e-01,  2.0326e-01, -2.3859e-01],\n",
       "          [-1.5125e-01, -1.5270e-01, -4.8517e-03],\n",
       "          [-1.2388e-01,  3.9389e-02, -1.1794e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.0285e-01, -6.2192e-02,  2.4233e-01],\n",
       "          [ 2.4259e-01, -1.6546e-01, -1.6715e-01],\n",
       "          [-5.6750e-02, -1.6205e-01,  1.7274e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.5219e-01, -1.9231e-01, -3.0295e-01],\n",
       "          [-2.4457e-01,  2.6070e-01,  2.1237e-01],\n",
       "          [ 1.7042e-01,  1.5803e-02,  7.6744e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.9582e-01, -1.9520e-01,  9.9242e-02],\n",
       "          [-2.5770e-01, -3.2273e-01, -7.7410e-02],\n",
       "          [-9.5875e-02, -1.7682e-01,  1.0747e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.1571e-01,  3.2541e-02,  8.5866e-02],\n",
       "          [ 6.3949e-02,  1.3171e-01, -1.6450e-01],\n",
       "          [-1.9385e-01,  2.0677e-02,  1.1998e-02]]],\n",
       "\n",
       "\n",
       "        [[[-7.0711e-02, -1.5900e-01, -2.4963e-01],\n",
       "          [ 2.5163e-01,  1.6847e-03,  2.1538e-01],\n",
       "          [-3.4085e-02, -7.5801e-02,  1.9304e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.2618e-01, -3.2111e-01, -1.3947e-01],\n",
       "          [ 1.6894e-02, -9.2725e-03, -8.2055e-02],\n",
       "          [-3.0557e-01, -2.1323e-02,  2.6003e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.2558e-01, -1.8523e-01,  1.2142e-01],\n",
       "          [ 1.7502e-02, -3.2701e-01, -1.2645e-01],\n",
       "          [-8.3149e-02,  1.2347e-01,  3.9001e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5706e-01,  1.3400e-02, -7.8242e-02],\n",
       "          [ 2.3044e-01,  1.5530e-01, -1.7781e-01],\n",
       "          [-6.6570e-02,  2.3941e-02,  3.2875e-01]]],\n",
       "\n",
       "\n",
       "        [[[-7.9470e-02,  9.9647e-02, -1.1108e-01],\n",
       "          [ 2.7848e-01,  2.3213e-04, -4.9797e-02],\n",
       "          [ 2.0724e-01,  2.5831e-01,  3.5849e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.9419e-01,  2.5526e-01,  1.3236e-02],\n",
       "          [ 8.8257e-02, -1.2690e-01, -7.7731e-02],\n",
       "          [ 3.2311e-02,  1.0193e-01,  3.0660e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.5397e-02,  1.1566e-01, -2.8066e-01],\n",
       "          [-1.9514e-01, -7.7377e-02,  2.7922e-01],\n",
       "          [ 2.2517e-01, -1.7826e-02,  2.7672e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.8358e-01, -2.2869e-01, -4.9394e-02],\n",
       "          [ 1.6017e-01,  2.8403e-01, -2.2653e-01],\n",
       "          [ 2.3246e-05,  1.3648e-01, -2.2549e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.7899e-01,  5.6280e-02,  2.0813e-01],\n",
       "          [ 6.1516e-02, -4.0183e-02,  5.0885e-02],\n",
       "          [-9.8551e-02, -1.9418e-01, -3.1992e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0220e-01, -1.3837e-01, -1.3171e-01],\n",
       "          [-2.6934e-01, -2.4807e-01, -1.5455e-01],\n",
       "          [ 1.6875e-01,  2.8055e-01, -2.6407e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.1808e-02, -2.9200e-01, -3.3046e-01],\n",
       "          [-6.1343e-02, -2.6554e-05, -7.9588e-03],\n",
       "          [ 2.6892e-01, -1.4662e-02,  1.9800e-01]]],\n",
       "\n",
       "\n",
       "        [[[-7.4911e-02, -2.9594e-01, -2.8759e-01],\n",
       "          [-8.0595e-02,  2.7489e-01, -1.5767e-01],\n",
       "          [-1.6080e-01, -9.6615e-02, -1.8993e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.7903e-02, -2.0771e-01,  2.0892e-01],\n",
       "          [ 2.7835e-01, -1.5096e-02, -1.5585e-01],\n",
       "          [-9.2454e-02, -1.1272e-01, -1.6070e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.1512e-01,  1.1668e-01,  1.0434e-01],\n",
       "          [ 7.2569e-02, -2.7139e-01, -1.4823e-01],\n",
       "          [ 5.1687e-02, -3.1201e-01,  9.9303e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0267e-01,  2.6145e-02, -2.3882e-02],\n",
       "          [-1.2724e-02, -3.2727e-02,  1.5315e-01],\n",
       "          [ 3.0951e-01,  4.6323e-02,  2.6627e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.3529e-01, -2.0573e-01, -2.0435e-01],\n",
       "          [-2.4761e-01, -8.6424e-02, -1.2700e-01],\n",
       "          [-2.9072e-01,  1.5545e-01,  1.8565e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1112e-01, -1.0500e-01,  7.2851e-02],\n",
       "          [ 1.9434e-01,  3.0204e-01,  1.6178e-01],\n",
       "          [-2.6585e-01,  1.6350e-01,  2.3379e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.1825e-01,  2.1845e-01,  1.1148e-02],\n",
       "          [-1.8642e-01, -2.5033e-01,  9.0611e-02],\n",
       "          [-2.7545e-01,  1.4899e-01,  6.7364e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 6.6522e-02, -3.6841e-02, -2.3820e-01],\n",
       "          [ 2.1602e-02,  1.3765e-01,  9.4870e-03],\n",
       "          [-1.3090e-01, -2.0117e-01, -2.1677e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.0659e-01,  6.2209e-02,  3.4893e-02],\n",
       "          [ 1.4694e-01,  1.8613e-01, -2.1667e-02],\n",
       "          [ 1.6077e-01,  2.7391e-01,  8.1851e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7705e-01,  3.1848e-01,  1.0092e-01],\n",
       "          [ 2.7513e-01, -2.7308e-01,  2.0595e-01],\n",
       "          [-1.5381e-01, -1.9864e-02, -3.0324e-01]]]], requires_grad=True)), ('features.conv1.bias', Parameter containing:\n",
       "tensor([ 0.0899,  0.0507, -0.0782, -0.1690, -0.2882,  0.2517, -0.2583, -0.0764,\n",
       "        -0.0736, -0.0721,  0.0182, -0.0322,  0.0293, -0.2790, -0.2696, -0.3073,\n",
       "         0.2384,  0.0212, -0.0347, -0.1500, -0.2425, -0.0683, -0.0535, -0.1270,\n",
       "         0.0841, -0.2656,  0.1925, -0.0413,  0.2163,  0.2532, -0.2341,  0.1484,\n",
       "         0.0272, -0.2992, -0.2951, -0.0554, -0.2142, -0.0491,  0.1129, -0.0183,\n",
       "        -0.1061,  0.2715,  0.2746, -0.0739,  0.0446, -0.1062,  0.2964,  0.0491,\n",
       "         0.1781,  0.0305, -0.0522,  0.2136, -0.2059, -0.0741,  0.2843, -0.0004,\n",
       "         0.3129,  0.0031,  0.1940,  0.0098,  0.1040, -0.3013,  0.1947, -0.1633],\n",
       "       requires_grad=True)), ('features.bn1.weight', Parameter containing:\n",
       "tensor([0.6982, 0.6375, 0.3329, 0.7467, 0.3255, 0.4384, 0.6465, 0.2276, 0.3996,\n",
       "        0.2202, 0.1898, 0.3228, 0.2346, 0.9019, 0.0983, 0.3745, 0.2895, 0.3253,\n",
       "        0.0318, 0.0191, 0.2182, 0.2754, 0.8890, 0.6304, 0.9511, 0.1695, 0.0183,\n",
       "        0.2345, 0.8358, 0.9978, 0.4638, 0.5600, 0.0835, 0.2921, 0.6897, 0.4141,\n",
       "        0.2116, 0.4424, 0.3548, 0.0189, 0.7917, 0.5266, 0.7723, 0.6386, 0.2016,\n",
       "        0.2242, 0.6579, 0.0478, 0.2280, 0.6628, 0.6005, 0.6724, 0.6659, 0.7232,\n",
       "        0.8436, 0.5121, 0.5594, 0.7774, 0.6240, 0.1343, 0.2477, 0.2767, 0.8069,\n",
       "        0.6123], requires_grad=True)), ('features.bn1.bias', Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       requires_grad=True)), ('features.conv2.weight', Parameter containing:\n",
       "tensor([[[[-0.0130,  0.0363, -0.0042],\n",
       "          [ 0.0168,  0.0089, -0.0207],\n",
       "          [ 0.0023, -0.0351, -0.0281]],\n",
       "\n",
       "         [[ 0.0032, -0.0098, -0.0022],\n",
       "          [ 0.0185, -0.0406, -0.0129],\n",
       "          [-0.0170,  0.0377,  0.0414]],\n",
       "\n",
       "         [[-0.0372,  0.0237, -0.0361],\n",
       "          [ 0.0392, -0.0021, -0.0167],\n",
       "          [ 0.0252,  0.0367,  0.0031]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0226,  0.0205, -0.0207],\n",
       "          [-0.0006,  0.0108, -0.0359],\n",
       "          [ 0.0095,  0.0393,  0.0352]],\n",
       "\n",
       "         [[-0.0391, -0.0407,  0.0338],\n",
       "          [-0.0313,  0.0144, -0.0408],\n",
       "          [-0.0274,  0.0003, -0.0174]],\n",
       "\n",
       "         [[ 0.0052,  0.0287, -0.0409],\n",
       "          [-0.0387,  0.0237, -0.0051],\n",
       "          [-0.0183,  0.0178,  0.0103]]],\n",
       "\n",
       "\n",
       "        [[[-0.0300, -0.0382, -0.0396],\n",
       "          [-0.0158,  0.0025,  0.0031],\n",
       "          [ 0.0292,  0.0004, -0.0114]],\n",
       "\n",
       "         [[-0.0401, -0.0065, -0.0103],\n",
       "          [-0.0035,  0.0181, -0.0213],\n",
       "          [ 0.0050, -0.0415,  0.0393]],\n",
       "\n",
       "         [[ 0.0349,  0.0293, -0.0055],\n",
       "          [-0.0209, -0.0399, -0.0051],\n",
       "          [-0.0272,  0.0403, -0.0002]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0127, -0.0295,  0.0051],\n",
       "          [-0.0331, -0.0293,  0.0123],\n",
       "          [-0.0241,  0.0416,  0.0195]],\n",
       "\n",
       "         [[ 0.0130,  0.0170, -0.0367],\n",
       "          [-0.0099, -0.0389, -0.0380],\n",
       "          [-0.0029,  0.0199, -0.0190]],\n",
       "\n",
       "         [[ 0.0416, -0.0414,  0.0352],\n",
       "          [ 0.0371, -0.0102, -0.0130],\n",
       "          [ 0.0395,  0.0373, -0.0132]]],\n",
       "\n",
       "\n",
       "        [[[-0.0260, -0.0064,  0.0214],\n",
       "          [-0.0187,  0.0351, -0.0293],\n",
       "          [-0.0335,  0.0380,  0.0245]],\n",
       "\n",
       "         [[ 0.0404,  0.0379,  0.0219],\n",
       "          [-0.0005,  0.0118,  0.0031],\n",
       "          [-0.0282, -0.0011,  0.0259]],\n",
       "\n",
       "         [[ 0.0059,  0.0126,  0.0301],\n",
       "          [-0.0247, -0.0110,  0.0221],\n",
       "          [ 0.0034,  0.0197,  0.0032]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0055,  0.0333, -0.0076],\n",
       "          [-0.0082, -0.0399,  0.0215],\n",
       "          [-0.0047, -0.0276,  0.0242]],\n",
       "\n",
       "         [[-0.0011,  0.0348,  0.0279],\n",
       "          [ 0.0320, -0.0036, -0.0400],\n",
       "          [ 0.0081, -0.0214, -0.0193]],\n",
       "\n",
       "         [[-0.0129, -0.0222, -0.0084],\n",
       "          [-0.0207, -0.0186,  0.0085],\n",
       "          [ 0.0275,  0.0095, -0.0191]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0320,  0.0118, -0.0286],\n",
       "          [-0.0186,  0.0112,  0.0079],\n",
       "          [-0.0027, -0.0324, -0.0240]],\n",
       "\n",
       "         [[ 0.0378, -0.0274,  0.0149],\n",
       "          [-0.0110, -0.0091,  0.0103],\n",
       "          [ 0.0300,  0.0001, -0.0361]],\n",
       "\n",
       "         [[-0.0100,  0.0142, -0.0122],\n",
       "          [-0.0410,  0.0298, -0.0051],\n",
       "          [ 0.0009, -0.0381, -0.0342]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0263,  0.0245, -0.0100],\n",
       "          [ 0.0281,  0.0089, -0.0270],\n",
       "          [-0.0306, -0.0300, -0.0270]],\n",
       "\n",
       "         [[-0.0307,  0.0222, -0.0228],\n",
       "          [ 0.0235,  0.0188, -0.0273],\n",
       "          [-0.0125,  0.0268,  0.0017]],\n",
       "\n",
       "         [[-0.0358, -0.0216,  0.0013],\n",
       "          [ 0.0174, -0.0318, -0.0282],\n",
       "          [-0.0286, -0.0115, -0.0308]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0257, -0.0207, -0.0382],\n",
       "          [ 0.0363,  0.0171,  0.0364],\n",
       "          [ 0.0361,  0.0168,  0.0077]],\n",
       "\n",
       "         [[-0.0407, -0.0262,  0.0148],\n",
       "          [ 0.0200,  0.0011, -0.0411],\n",
       "          [ 0.0377, -0.0390, -0.0330]],\n",
       "\n",
       "         [[ 0.0349, -0.0076,  0.0065],\n",
       "          [ 0.0323,  0.0029,  0.0027],\n",
       "          [ 0.0248, -0.0237,  0.0207]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0397, -0.0334,  0.0238],\n",
       "          [ 0.0148,  0.0320,  0.0377],\n",
       "          [ 0.0034, -0.0374, -0.0201]],\n",
       "\n",
       "         [[ 0.0274,  0.0147, -0.0398],\n",
       "          [ 0.0064,  0.0168,  0.0144],\n",
       "          [-0.0141,  0.0066, -0.0098]],\n",
       "\n",
       "         [[ 0.0120,  0.0213, -0.0056],\n",
       "          [ 0.0202,  0.0278, -0.0134],\n",
       "          [-0.0356,  0.0200,  0.0358]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0040,  0.0122,  0.0027],\n",
       "          [-0.0348,  0.0010, -0.0208],\n",
       "          [-0.0333,  0.0386, -0.0163]],\n",
       "\n",
       "         [[-0.0115, -0.0401,  0.0195],\n",
       "          [ 0.0214,  0.0113, -0.0213],\n",
       "          [ 0.0391,  0.0003, -0.0276]],\n",
       "\n",
       "         [[-0.0289,  0.0108,  0.0228],\n",
       "          [-0.0032,  0.0217,  0.0357],\n",
       "          [ 0.0105, -0.0289, -0.0275]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0061,  0.0166,  0.0377],\n",
       "          [-0.0298,  0.0219, -0.0115],\n",
       "          [ 0.0157,  0.0327,  0.0281]],\n",
       "\n",
       "         [[ 0.0101, -0.0254, -0.0039],\n",
       "          [ 0.0334, -0.0230,  0.0197],\n",
       "          [ 0.0342,  0.0391,  0.0340]],\n",
       "\n",
       "         [[ 0.0122, -0.0108, -0.0246],\n",
       "          [ 0.0378, -0.0020,  0.0223],\n",
       "          [-0.0023,  0.0207,  0.0342]]]], requires_grad=True)), ('features.conv2.bias', Parameter containing:\n",
       "tensor([-0.0278,  0.0152,  0.0088,  0.0076, -0.0215, -0.0050,  0.0226, -0.0017,\n",
       "        -0.0354, -0.0357,  0.0116, -0.0133, -0.0182,  0.0220, -0.0308, -0.0397,\n",
       "        -0.0289, -0.0111, -0.0245,  0.0297,  0.0213, -0.0313, -0.0210, -0.0181,\n",
       "         0.0130,  0.0416,  0.0160,  0.0098,  0.0287, -0.0257,  0.0225,  0.0023,\n",
       "         0.0022,  0.0189, -0.0329,  0.0211,  0.0029,  0.0241,  0.0239,  0.0190,\n",
       "        -0.0212,  0.0364,  0.0411, -0.0417,  0.0371, -0.0289,  0.0193, -0.0129,\n",
       "         0.0024, -0.0368,  0.0264,  0.0145,  0.0221, -0.0350,  0.0191,  0.0015,\n",
       "        -0.0114,  0.0206,  0.0242,  0.0175, -0.0034, -0.0177, -0.0285,  0.0112],\n",
       "       requires_grad=True)), ('features.bn2.weight', Parameter containing:\n",
       "tensor([0.0978, 0.8158, 0.2650, 0.1968, 0.8132, 0.7244, 0.3902, 0.4539, 0.1474,\n",
       "        0.6478, 0.4669, 0.8806, 0.9630, 0.2123, 0.2354, 0.5022, 0.6939, 0.0399,\n",
       "        0.7175, 0.8386, 0.4766, 0.9133, 0.8717, 0.3504, 0.2156, 0.1351, 0.1273,\n",
       "        0.8069, 0.4631, 0.5751, 0.8606, 0.1844, 0.9914, 0.5906, 0.8693, 0.1625,\n",
       "        0.1732, 0.9177, 0.6386, 0.6017, 0.5011, 0.5333, 0.3780, 0.0785, 0.4844,\n",
       "        0.0654, 0.0713, 0.8116, 0.3916, 0.4081, 0.3419, 0.8921, 0.5254, 0.2379,\n",
       "        0.1955, 0.0432, 0.1075, 0.6585, 0.6384, 0.5262, 0.2597, 0.5312, 0.5360,\n",
       "        0.3270], requires_grad=True)), ('features.bn2.bias', Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       requires_grad=True)), ('features.conv3.weight', Parameter containing:\n",
       "tensor([[[[-3.2427e-02, -2.5656e-02,  2.3543e-02],\n",
       "          [-2.9180e-02,  3.3374e-03,  1.3070e-02],\n",
       "          [-4.1547e-02, -3.9488e-02,  2.9841e-02]],\n",
       "\n",
       "         [[-2.5536e-02,  4.0381e-02, -2.4869e-02],\n",
       "          [ 1.8815e-02,  1.3836e-02, -3.0915e-02],\n",
       "          [ 2.3917e-02,  3.2516e-02,  3.9471e-02]],\n",
       "\n",
       "         [[-3.3998e-02,  2.9386e-02, -1.8287e-02],\n",
       "          [-2.9685e-03, -1.6066e-02,  1.7344e-02],\n",
       "          [ 9.3686e-03,  3.6282e-02,  1.1014e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.0739e-02, -2.4947e-02,  1.3525e-02],\n",
       "          [-1.5668e-02,  1.1070e-02, -2.2116e-02],\n",
       "          [-1.7611e-02, -2.5645e-02,  2.9328e-02]],\n",
       "\n",
       "         [[-3.7357e-02,  1.9776e-02,  2.1376e-02],\n",
       "          [-2.2506e-02, -4.1345e-02, -3.5598e-02],\n",
       "          [ 2.3481e-02, -3.8778e-02, -3.9479e-02]],\n",
       "\n",
       "         [[ 3.0839e-02,  2.6462e-02, -3.9669e-02],\n",
       "          [-2.8227e-02, -2.3345e-02,  3.3547e-02],\n",
       "          [-3.4016e-02,  1.1669e-02,  8.6124e-04]]],\n",
       "\n",
       "\n",
       "        [[[-3.5436e-02,  9.2653e-03,  2.3578e-02],\n",
       "          [-1.1689e-02,  3.8797e-03, -1.7672e-02],\n",
       "          [ 1.0861e-03,  1.5437e-02, -1.2176e-02]],\n",
       "\n",
       "         [[ 2.9635e-02,  3.2387e-03, -4.4620e-03],\n",
       "          [-1.1618e-02,  3.9223e-02,  4.0398e-02],\n",
       "          [-2.3916e-02,  3.4547e-02, -7.1994e-03]],\n",
       "\n",
       "         [[ 4.0802e-02, -7.4381e-03, -8.4392e-03],\n",
       "          [ 2.9054e-02, -1.7901e-02, -2.9488e-02],\n",
       "          [-1.0242e-02, -1.8972e-02,  1.4508e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.9378e-02,  3.4769e-02,  2.3636e-02],\n",
       "          [-3.2452e-02, -9.4816e-03,  2.9582e-02],\n",
       "          [ 3.5816e-02, -2.6352e-03,  9.8730e-03]],\n",
       "\n",
       "         [[-1.9615e-02, -1.5446e-02,  7.7801e-03],\n",
       "          [-2.6655e-02,  1.4050e-02, -1.8495e-02],\n",
       "          [ 2.6021e-02,  3.9952e-02, -3.1646e-02]],\n",
       "\n",
       "         [[ 3.6165e-02, -2.7755e-02,  8.6317e-03],\n",
       "          [ 3.2892e-02,  4.0851e-02,  1.8647e-03],\n",
       "          [ 1.6926e-02,  5.6931e-03, -9.9183e-03]]],\n",
       "\n",
       "\n",
       "        [[[-2.9153e-02,  1.1222e-02,  3.5782e-02],\n",
       "          [-3.9189e-02, -4.1281e-02, -2.8683e-02],\n",
       "          [ 2.1050e-02,  2.8494e-02, -2.8853e-02]],\n",
       "\n",
       "         [[-2.4005e-02, -3.2241e-02,  9.5249e-03],\n",
       "          [ 1.9821e-02, -3.0194e-02, -4.1240e-02],\n",
       "          [-1.3161e-02,  8.9709e-03,  1.0424e-02]],\n",
       "\n",
       "         [[-2.8677e-02, -8.4116e-03, -2.4566e-02],\n",
       "          [-1.8973e-02, -4.0501e-02, -2.6735e-03],\n",
       "          [-2.0932e-02, -1.7012e-03,  4.0665e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.5645e-02, -1.5130e-02,  1.6669e-02],\n",
       "          [-2.5688e-02, -3.9143e-02, -3.2533e-02],\n",
       "          [-3.8713e-02,  3.1537e-02, -3.1544e-02]],\n",
       "\n",
       "         [[-3.1895e-02,  2.1145e-03,  1.1041e-02],\n",
       "          [ 4.0536e-02, -3.6209e-02,  3.5161e-02],\n",
       "          [ 2.0571e-02,  2.9659e-02,  6.2102e-03]],\n",
       "\n",
       "         [[-3.8973e-02, -8.7100e-03,  3.9577e-02],\n",
       "          [-2.1251e-02,  2.1324e-02,  8.7069e-03],\n",
       "          [-7.2928e-03, -2.6461e-02, -4.0386e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.0568e-02, -2.0623e-02, -4.1276e-02],\n",
       "          [ 2.1856e-02, -2.3624e-02, -1.1486e-02],\n",
       "          [-3.3172e-02,  9.6587e-03,  6.6622e-03]],\n",
       "\n",
       "         [[-1.3452e-02, -3.8756e-02,  3.5332e-02],\n",
       "          [ 1.3796e-02,  3.8010e-02, -7.5744e-03],\n",
       "          [-2.0450e-02, -3.0653e-02,  3.4297e-02]],\n",
       "\n",
       "         [[-2.2635e-02, -1.1953e-02, -2.6365e-02],\n",
       "          [-2.4008e-02, -3.3582e-02,  2.8460e-02],\n",
       "          [-1.9457e-02,  1.7204e-02,  1.2802e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9134e-02, -2.0726e-02, -2.7004e-02],\n",
       "          [ 5.3172e-03, -1.1014e-03, -3.2828e-02],\n",
       "          [ 1.5795e-02, -1.0875e-02, -2.2756e-02]],\n",
       "\n",
       "         [[-5.8243e-03, -9.2174e-03,  8.5622e-03],\n",
       "          [-3.6112e-02, -8.1241e-03, -1.8991e-02],\n",
       "          [ 2.0626e-02, -1.2135e-02,  3.6191e-02]],\n",
       "\n",
       "         [[ 2.5137e-02, -2.0581e-02,  1.7079e-02],\n",
       "          [ 2.2579e-02,  2.6709e-02, -6.5927e-03],\n",
       "          [ 2.3317e-02,  6.6358e-03,  8.5952e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.6816e-02, -2.8769e-02,  2.6426e-02],\n",
       "          [ 6.3933e-03,  3.4745e-02, -5.3216e-03],\n",
       "          [ 1.3235e-02, -5.9389e-03,  2.8185e-02]],\n",
       "\n",
       "         [[-1.1891e-02,  4.0013e-02, -9.2943e-03],\n",
       "          [ 1.6283e-02, -3.1457e-02, -4.3971e-03],\n",
       "          [-4.1431e-02,  2.6374e-02, -3.5776e-02]],\n",
       "\n",
       "         [[ 1.0622e-02,  2.9528e-02, -2.8861e-02],\n",
       "          [ 2.9193e-02, -4.0053e-02, -1.4846e-02],\n",
       "          [ 2.6955e-03,  9.2096e-03, -1.2256e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.5018e-03, -2.1345e-02,  2.6936e-02],\n",
       "          [ 1.6902e-02, -6.0368e-05,  2.3382e-02],\n",
       "          [-1.8792e-02, -2.0039e-02,  1.0439e-02]],\n",
       "\n",
       "         [[-1.4893e-02,  1.4719e-02,  3.8570e-03],\n",
       "          [ 3.3486e-03, -1.4629e-02,  1.5128e-02],\n",
       "          [ 3.0593e-02,  1.8648e-02, -1.8732e-02]],\n",
       "\n",
       "         [[-2.7297e-02,  3.0437e-02, -2.3435e-02],\n",
       "          [ 2.0480e-02, -3.5585e-02, -3.3455e-02],\n",
       "          [-1.4854e-03, -3.3639e-02, -3.3794e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.5174e-02,  8.5490e-03, -1.2323e-02],\n",
       "          [ 2.0669e-02, -3.0116e-02, -5.9842e-03],\n",
       "          [ 3.4862e-02,  2.6854e-02,  3.5678e-02]],\n",
       "\n",
       "         [[-7.4043e-03,  4.9456e-03, -9.9595e-03],\n",
       "          [-3.7400e-03, -1.6249e-02, -3.5140e-02],\n",
       "          [ 2.5084e-02,  2.5079e-02,  4.0109e-02]],\n",
       "\n",
       "         [[ 1.6277e-02,  1.3413e-02,  9.2732e-04],\n",
       "          [-2.8328e-02, -4.1570e-02, -2.3975e-02],\n",
       "          [ 1.9192e-02,  2.8475e-02, -2.5891e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.7772e-02,  3.3041e-02,  3.8138e-02],\n",
       "          [-1.8397e-03,  4.0428e-02, -2.9087e-03],\n",
       "          [-3.3495e-03,  1.2920e-02,  2.4854e-02]],\n",
       "\n",
       "         [[ 3.3486e-02,  2.0107e-02,  2.6765e-02],\n",
       "          [-3.0747e-02, -2.1369e-02, -3.9857e-02],\n",
       "          [-1.6215e-02,  1.4522e-02, -2.0163e-02]],\n",
       "\n",
       "         [[-3.2599e-02,  1.0520e-02, -1.0591e-02],\n",
       "          [ 2.1557e-02, -1.1457e-03,  1.4254e-02],\n",
       "          [ 2.5567e-02, -1.1716e-02,  3.5229e-02]]]], requires_grad=True)), ('features.conv3.bias', Parameter containing:\n",
       "tensor([ 0.0407,  0.0345,  0.0275,  0.0363,  0.0066, -0.0102,  0.0261, -0.0282,\n",
       "         0.0050, -0.0065,  0.0372,  0.0186, -0.0074, -0.0177, -0.0276, -0.0343,\n",
       "        -0.0389, -0.0311,  0.0369,  0.0107,  0.0161,  0.0142, -0.0069,  0.0149,\n",
       "         0.0260, -0.0113, -0.0161, -0.0360,  0.0015, -0.0201, -0.0148,  0.0189,\n",
       "         0.0158, -0.0129, -0.0361, -0.0245,  0.0071, -0.0085,  0.0250,  0.0202,\n",
       "        -0.0108, -0.0278, -0.0268,  0.0129,  0.0188, -0.0243, -0.0004,  0.0249,\n",
       "        -0.0048, -0.0309,  0.0361,  0.0155,  0.0138,  0.0094,  0.0352,  0.0214,\n",
       "         0.0402,  0.0025, -0.0231,  0.0367, -0.0035, -0.0229,  0.0023, -0.0122],\n",
       "       requires_grad=True)), ('features.bn3.weight', Parameter containing:\n",
       "tensor([0.8127, 0.7668, 0.9740, 0.5409, 0.1071, 0.1449, 0.8754, 0.2890, 0.7674,\n",
       "        0.2709, 0.9531, 0.8499, 0.5113, 0.7222, 0.7240, 0.2556, 0.0077, 0.8027,\n",
       "        0.3006, 0.1352, 0.4788, 0.8285, 0.5273, 0.7234, 0.4353, 0.3076, 0.4963,\n",
       "        0.9066, 0.1663, 0.5731, 0.1793, 0.3897, 0.4454, 0.3945, 0.1473, 0.3187,\n",
       "        0.2660, 0.3913, 0.7822, 0.3013, 0.7869, 0.1100, 0.6719, 0.3380, 0.3511,\n",
       "        0.6490, 0.0999, 0.9880, 0.2826, 0.1263, 0.3357, 0.9700, 0.7869, 0.5361,\n",
       "        0.2620, 0.6908, 0.8747, 0.3693, 0.9693, 0.3660, 0.5824, 0.2542, 0.8417,\n",
       "        0.7737], requires_grad=True)), ('features.bn3.bias', Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       requires_grad=True)), ('fc.weight', Parameter containing:\n",
       "tensor([[-0.0090, -0.0739,  0.0433, -0.0672, -0.0423, -0.0518,  0.0071, -0.0511,\n",
       "          0.0851, -0.0468,  0.0739, -0.0903,  0.0925, -0.0628,  0.0191, -0.1044,\n",
       "          0.0843,  0.1247, -0.1248, -0.0441, -0.0973, -0.0941, -0.0428,  0.0590,\n",
       "          0.1046,  0.1162,  0.0177,  0.0274, -0.1173,  0.0761,  0.0710,  0.0667,\n",
       "          0.0811, -0.1108, -0.0494,  0.0134, -0.0534, -0.0645, -0.0004,  0.0607,\n",
       "         -0.0963, -0.0577,  0.0868, -0.0262,  0.1153,  0.0373,  0.0240, -0.0019,\n",
       "         -0.1130, -0.0695,  0.0687, -0.0388,  0.0029, -0.1043, -0.0032,  0.0683,\n",
       "         -0.0861,  0.1160, -0.1143,  0.0143, -0.0591, -0.1105, -0.0330, -0.1154],\n",
       "        [ 0.0893,  0.0218, -0.1078,  0.0933, -0.0827, -0.0385, -0.0303,  0.0130,\n",
       "         -0.0279, -0.0457, -0.0269, -0.0734,  0.0457,  0.0626, -0.1041, -0.0346,\n",
       "          0.0116,  0.0250, -0.0572,  0.0079, -0.1135, -0.1006,  0.0565, -0.0587,\n",
       "          0.0164, -0.0139,  0.0603, -0.0927, -0.0121,  0.0295,  0.1059, -0.0551,\n",
       "          0.1215, -0.0291, -0.1103, -0.1206, -0.0827,  0.0951, -0.0949,  0.0578,\n",
       "          0.0085, -0.0617,  0.0530,  0.0258, -0.0041, -0.1140, -0.0265,  0.0433,\n",
       "         -0.0152, -0.0295, -0.0283, -0.1112, -0.1031, -0.1106,  0.0929, -0.1248,\n",
       "          0.0575,  0.1185,  0.0440, -0.0597,  0.0069, -0.0541,  0.1230,  0.0702],\n",
       "        [-0.1153,  0.0180,  0.0037, -0.0425, -0.0235, -0.0992, -0.0336,  0.0178,\n",
       "          0.1017, -0.0100,  0.0786,  0.0723,  0.0117,  0.0972, -0.0731, -0.0264,\n",
       "         -0.0566,  0.0424, -0.1043, -0.0246,  0.0211,  0.1184, -0.0958, -0.0357,\n",
       "          0.0763,  0.0739,  0.0122, -0.0406,  0.0640,  0.0646,  0.0851,  0.1193,\n",
       "          0.0921, -0.1071,  0.0959, -0.0286,  0.0598, -0.0341,  0.0291, -0.0046,\n",
       "         -0.1042,  0.0203,  0.0658,  0.0181,  0.0877, -0.0320,  0.1152, -0.0317,\n",
       "          0.0093, -0.0094,  0.0890, -0.0437,  0.0945,  0.0371, -0.0058,  0.0869,\n",
       "         -0.0233, -0.0388, -0.1045, -0.1244,  0.0744, -0.1012, -0.0967, -0.0570],\n",
       "        [-0.0466, -0.1168,  0.0315,  0.0005,  0.0767,  0.1225,  0.0350, -0.0054,\n",
       "         -0.0748, -0.0073, -0.0110, -0.0244,  0.0351,  0.0678, -0.0297,  0.1013,\n",
       "         -0.0606,  0.0118,  0.0992,  0.0350,  0.0028,  0.0070,  0.0771, -0.0086,\n",
       "         -0.0140, -0.0720,  0.0351,  0.0187,  0.0354,  0.0153,  0.1182,  0.0136,\n",
       "         -0.0172, -0.0308,  0.0527, -0.0003,  0.0851, -0.1035, -0.0082, -0.0562,\n",
       "          0.0616, -0.0145,  0.0591,  0.1008,  0.0171, -0.1089,  0.1105,  0.1219,\n",
       "         -0.0261,  0.0647,  0.0147, -0.0645, -0.0678,  0.0663,  0.0634,  0.0518,\n",
       "         -0.1117,  0.0438,  0.0482,  0.0859, -0.0768, -0.1175, -0.0923,  0.0356],\n",
       "        [ 0.1098,  0.0421, -0.0302,  0.0667,  0.0375,  0.0526,  0.0884, -0.0684,\n",
       "          0.1187,  0.0939, -0.0903,  0.1152,  0.1094, -0.0790, -0.0859, -0.0031,\n",
       "         -0.0649, -0.0679,  0.0180, -0.0757, -0.0925,  0.0278,  0.0811, -0.1016,\n",
       "          0.0650, -0.1018, -0.1145,  0.0659, -0.0851,  0.0140, -0.0999, -0.0891,\n",
       "         -0.0054, -0.1220, -0.0952, -0.0666, -0.1055,  0.0889, -0.1239, -0.0054,\n",
       "          0.0887, -0.0952, -0.0514, -0.0003,  0.0477,  0.0728,  0.0450, -0.1036,\n",
       "         -0.0404,  0.0969, -0.0343, -0.0858, -0.1034, -0.0994, -0.0896,  0.0924,\n",
       "          0.0428, -0.0798,  0.0793, -0.0173,  0.0189,  0.0111, -0.0991, -0.1095]],\n",
       "       requires_grad=True)), ('fc.bias', Parameter containing:\n",
       "tensor([-0.0351, -0.0600,  0.1078,  0.0130,  0.0041], requires_grad=True))])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=ConvNet(5)\n",
    "weights=OrderedDict((name, param) for (name,param) in net.named_parameters())\n",
    "weights.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('features.conv1.weight', tensor([[[[ 1.9403e-01, -2.3679e-01,  1.5356e-02],\n",
       "          [ 1.7192e-01, -1.7619e-01, -5.1181e-02],\n",
       "          [ 2.6803e-01,  1.4945e-01, -2.5490e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5718e-01,  2.5654e-01, -6.4612e-02],\n",
       "          [ 1.2119e-01, -1.5504e-01, -2.9659e-01],\n",
       "          [ 1.9620e-02, -1.9034e-01,  9.5991e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 2.3084e-01,  1.7164e-01,  2.7283e-02],\n",
       "          [ 2.6726e-01,  7.3758e-02,  5.6239e-02],\n",
       "          [ 1.4174e-01,  1.0790e-02,  9.6042e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.6255e-01, -3.1555e-01, -1.8513e-01],\n",
       "          [-1.3194e-01, -3.2913e-01,  2.7115e-01],\n",
       "          [-2.6304e-02, -5.0627e-02,  1.5131e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.6226e-01,  2.4513e-02, -2.6430e-01],\n",
       "          [-5.9958e-02,  8.8895e-02,  1.0743e-01],\n",
       "          [-2.3213e-01,  1.1048e-01,  2.3489e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.4756e-03,  1.4024e-01, -2.9164e-01],\n",
       "          [-1.3479e-01, -1.9207e-01, -2.0314e-01],\n",
       "          [-2.7353e-01,  2.6142e-01, -2.3706e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.6504e-01, -2.2353e-01,  1.1712e-01],\n",
       "          [ 1.1956e-01,  2.7649e-01, -2.0259e-01],\n",
       "          [-1.8710e-01,  3.1176e-01,  1.5528e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.9413e-01,  4.8424e-02,  7.3889e-02],\n",
       "          [-2.1505e-01,  1.1044e-01,  7.4240e-03],\n",
       "          [ 2.4389e-01,  2.1123e-02,  2.8800e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.0203e-01,  1.7662e-01,  9.0156e-02],\n",
       "          [ 1.1433e-01,  4.3281e-02, -2.6110e-01],\n",
       "          [-1.8114e-03,  1.6414e-02, -1.4127e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.2693e-01,  2.7209e-01,  3.0499e-01],\n",
       "          [ 3.2873e-01,  2.6905e-01, -1.6718e-01],\n",
       "          [-2.0653e-01, -5.9710e-02,  2.3277e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.3998e-02, -2.4578e-01, -6.9340e-02],\n",
       "          [-2.2031e-02, -1.6389e-01, -2.2158e-01],\n",
       "          [ 3.1846e-01,  2.7232e-01, -2.6582e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.9549e-02,  1.9524e-01,  1.5026e-01],\n",
       "          [ 3.0669e-01, -1.3532e-01,  1.3945e-01],\n",
       "          [-5.0661e-02,  2.8519e-01,  2.5853e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.8989e-01, -2.7323e-01, -1.1192e-01],\n",
       "          [-2.3421e-01,  9.5503e-03,  1.4764e-01],\n",
       "          [-3.2046e-01,  1.9271e-01, -7.0710e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.0166e-02, -1.8641e-01,  1.0686e-01],\n",
       "          [-2.2099e-02,  3.0623e-01,  2.7592e-01],\n",
       "          [ 2.5635e-01, -1.7342e-01, -5.6145e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.4874e-01,  2.7465e-01, -3.2786e-01],\n",
       "          [ 2.2477e-01,  1.0441e-01,  2.4889e-01],\n",
       "          [ 3.2103e-01,  2.0313e-01,  1.7142e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.6733e-01,  2.4837e-01, -1.8885e-01],\n",
       "          [-1.9981e-01, -1.5662e-01, -5.3461e-02],\n",
       "          [-2.7634e-01, -3.0709e-01,  2.5937e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1665e-01, -1.6399e-01, -2.6459e-01],\n",
       "          [ 1.6116e-01,  1.7416e-01,  1.7834e-01],\n",
       "          [ 1.9056e-01,  2.8698e-01, -9.8499e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.1810e-01, -4.9093e-02, -2.6480e-01],\n",
       "          [ 2.5131e-01,  6.3317e-02, -2.9737e-01],\n",
       "          [-2.3195e-01,  1.6001e-01, -5.9193e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.8614e-01,  3.2996e-01, -8.0062e-03],\n",
       "          [-2.4581e-01, -2.0412e-01,  2.8860e-01],\n",
       "          [-2.5793e-01, -8.7393e-02,  1.7483e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.7391e-02, -2.7927e-01, -9.2478e-02],\n",
       "          [-9.4458e-02, -2.5115e-01,  9.4550e-02],\n",
       "          [-1.8366e-02, -1.7751e-01, -1.0278e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4758e-01, -2.9636e-02,  8.8756e-02],\n",
       "          [-2.5943e-01,  8.4606e-03, -2.5821e-01],\n",
       "          [-1.7132e-01,  6.2946e-02, -3.0753e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.0381e-01,  1.7786e-01, -3.1917e-01],\n",
       "          [-2.9734e-01,  2.6453e-02,  3.0631e-01],\n",
       "          [ 4.2392e-02,  2.9294e-01, -1.2679e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.4424e-01, -2.2995e-01, -1.5987e-01],\n",
       "          [-2.7159e-01,  1.3120e-01, -2.5056e-01],\n",
       "          [-3.1768e-01, -2.5544e-01, -1.1304e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.7021e-02, -3.2938e-01,  3.2461e-01],\n",
       "          [-9.5205e-02,  1.5636e-02, -7.3437e-02],\n",
       "          [ 7.5658e-02,  4.6498e-02, -1.4871e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1671e-01, -2.7321e-01, -2.3820e-01],\n",
       "          [ 1.1419e-01,  1.5681e-01,  2.1927e-01],\n",
       "          [ 2.5088e-01, -2.6716e-01, -1.3429e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.3192e-01, -1.8204e-01, -1.0673e-01],\n",
       "          [ 7.0971e-02, -2.7763e-01, -1.8504e-01],\n",
       "          [ 3.2189e-01,  1.3033e-01,  3.1698e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9771e-01,  2.5434e-02,  7.8876e-02],\n",
       "          [ 1.6489e-01, -5.9994e-02,  1.6280e-01],\n",
       "          [ 2.8181e-01,  2.2979e-01, -1.3474e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.6066e-02,  2.7027e-01,  2.8091e-01],\n",
       "          [ 1.7132e-01, -2.3974e-01, -1.1792e-01],\n",
       "          [ 2.1913e-01,  3.2234e-01,  1.2347e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.5605e-02, -2.0139e-01,  1.3552e-02],\n",
       "          [-1.4517e-01, -8.5627e-02, -1.9015e-01],\n",
       "          [-8.2532e-02,  2.3770e-01,  2.1721e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7520e-01,  1.6083e-01,  1.8358e-01],\n",
       "          [-1.5117e-01, -4.7603e-02,  2.4597e-01],\n",
       "          [ 1.8075e-01,  1.2369e-01,  1.7698e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.5584e-01,  8.7248e-02, -2.7769e-01],\n",
       "          [-2.8667e-01, -1.8832e-01, -2.2002e-01],\n",
       "          [-2.5631e-01,  1.3233e-01,  1.2819e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.9341e-01,  2.1483e-01,  2.0220e-01],\n",
       "          [ 6.7487e-02,  1.3458e-01,  7.0740e-02],\n",
       "          [-1.0161e-01,  3.3311e-01, -3.1730e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.1976e-01, -9.0420e-02,  2.5396e-01],\n",
       "          [-3.2438e-01,  3.2478e-01, -2.5863e-01],\n",
       "          [-2.2571e-01, -3.6290e-02,  3.1173e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.8144e-01, -2.4694e-01,  1.5229e-01],\n",
       "          [ 2.9971e-01,  3.7035e-04, -1.4650e-01],\n",
       "          [-4.0739e-02,  2.0064e-01,  1.7328e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9597e-01, -2.6515e-01, -4.0890e-02],\n",
       "          [-3.1321e-01,  1.2351e-01, -2.4245e-02],\n",
       "          [ 1.0272e-01,  1.5957e-01, -2.5693e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.2003e-01, -2.4574e-01, -1.7039e-01],\n",
       "          [ 2.3889e-01,  2.4357e-01,  1.1597e-01],\n",
       "          [-8.0086e-02, -1.4114e-01,  3.1642e-01]]],\n",
       "\n",
       "\n",
       "        [[[-5.0903e-02, -1.2799e-01, -2.0979e-01],\n",
       "          [ 1.1122e-01,  1.0288e-01,  3.1154e-01],\n",
       "          [ 1.2442e-01,  1.8975e-01, -5.2172e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 5.1343e-02,  2.9489e-01, -5.5724e-02],\n",
       "          [ 2.7941e-01,  9.7155e-02, -1.4125e-01],\n",
       "          [-1.0445e-02,  2.7509e-01,  1.1658e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5793e-01,  2.0326e-01, -2.3859e-01],\n",
       "          [-1.5125e-01, -1.5270e-01, -4.8517e-03],\n",
       "          [-1.2388e-01,  3.9389e-02, -1.1794e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.0285e-01, -6.2192e-02,  2.4233e-01],\n",
       "          [ 2.4259e-01, -1.6546e-01, -1.6715e-01],\n",
       "          [-5.6750e-02, -1.6205e-01,  1.7274e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.5219e-01, -1.9231e-01, -3.0295e-01],\n",
       "          [-2.4457e-01,  2.6070e-01,  2.1237e-01],\n",
       "          [ 1.7042e-01,  1.5803e-02,  7.6744e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.9582e-01, -1.9520e-01,  9.9242e-02],\n",
       "          [-2.5770e-01, -3.2273e-01, -7.7410e-02],\n",
       "          [-9.5875e-02, -1.7682e-01,  1.0747e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.1571e-01,  3.2541e-02,  8.5866e-02],\n",
       "          [ 6.3949e-02,  1.3171e-01, -1.6450e-01],\n",
       "          [-1.9385e-01,  2.0677e-02,  1.1998e-02]]],\n",
       "\n",
       "\n",
       "        [[[-7.0711e-02, -1.5900e-01, -2.4963e-01],\n",
       "          [ 2.5163e-01,  1.6847e-03,  2.1538e-01],\n",
       "          [-3.4085e-02, -7.5801e-02,  1.9304e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.2618e-01, -3.2111e-01, -1.3947e-01],\n",
       "          [ 1.6894e-02, -9.2725e-03, -8.2055e-02],\n",
       "          [-3.0557e-01, -2.1323e-02,  2.6003e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.2558e-01, -1.8523e-01,  1.2142e-01],\n",
       "          [ 1.7502e-02, -3.2701e-01, -1.2645e-01],\n",
       "          [-8.3149e-02,  1.2347e-01,  3.9001e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.5706e-01,  1.3400e-02, -7.8242e-02],\n",
       "          [ 2.3044e-01,  1.5530e-01, -1.7781e-01],\n",
       "          [-6.6570e-02,  2.3941e-02,  3.2875e-01]]],\n",
       "\n",
       "\n",
       "        [[[-7.9470e-02,  9.9647e-02, -1.1108e-01],\n",
       "          [ 2.7848e-01,  2.3213e-04, -4.9797e-02],\n",
       "          [ 2.0724e-01,  2.5831e-01,  3.5849e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.9419e-01,  2.5526e-01,  1.3236e-02],\n",
       "          [ 8.8257e-02, -1.2690e-01, -7.7731e-02],\n",
       "          [ 3.2311e-02,  1.0193e-01,  3.0660e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.5397e-02,  1.1566e-01, -2.8066e-01],\n",
       "          [-1.9514e-01, -7.7377e-02,  2.7922e-01],\n",
       "          [ 2.2517e-01, -1.7826e-02,  2.7672e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.8358e-01, -2.2869e-01, -4.9394e-02],\n",
       "          [ 1.6017e-01,  2.8403e-01, -2.2653e-01],\n",
       "          [ 2.3246e-05,  1.3648e-01, -2.2549e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.7899e-01,  5.6280e-02,  2.0813e-01],\n",
       "          [ 6.1516e-02, -4.0183e-02,  5.0885e-02],\n",
       "          [-9.8551e-02, -1.9418e-01, -3.1992e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0220e-01, -1.3837e-01, -1.3171e-01],\n",
       "          [-2.6934e-01, -2.4807e-01, -1.5455e-01],\n",
       "          [ 1.6875e-01,  2.8055e-01, -2.6407e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.1808e-02, -2.9200e-01, -3.3046e-01],\n",
       "          [-6.1343e-02, -2.6554e-05, -7.9588e-03],\n",
       "          [ 2.6892e-01, -1.4662e-02,  1.9800e-01]]],\n",
       "\n",
       "\n",
       "        [[[-7.4911e-02, -2.9594e-01, -2.8759e-01],\n",
       "          [-8.0595e-02,  2.7489e-01, -1.5767e-01],\n",
       "          [-1.6080e-01, -9.6615e-02, -1.8993e-01]]],\n",
       "\n",
       "\n",
       "        [[[-8.7903e-02, -2.0771e-01,  2.0892e-01],\n",
       "          [ 2.7835e-01, -1.5096e-02, -1.5585e-01],\n",
       "          [-9.2454e-02, -1.1272e-01, -1.6070e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.1512e-01,  1.1668e-01,  1.0434e-01],\n",
       "          [ 7.2569e-02, -2.7139e-01, -1.4823e-01],\n",
       "          [ 5.1687e-02, -3.1201e-01,  9.9303e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 2.0267e-01,  2.6145e-02, -2.3882e-02],\n",
       "          [-1.2724e-02, -3.2727e-02,  1.5315e-01],\n",
       "          [ 3.0951e-01,  4.6323e-02,  2.6627e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.3529e-01, -2.0573e-01, -2.0435e-01],\n",
       "          [-2.4761e-01, -8.6424e-02, -1.2700e-01],\n",
       "          [-2.9072e-01,  1.5545e-01,  1.8565e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1112e-01, -1.0500e-01,  7.2851e-02],\n",
       "          [ 1.9434e-01,  3.0204e-01,  1.6178e-01],\n",
       "          [-2.6585e-01,  1.6350e-01,  2.3379e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.1825e-01,  2.1845e-01,  1.1148e-02],\n",
       "          [-1.8642e-01, -2.5033e-01,  9.0611e-02],\n",
       "          [-2.7545e-01,  1.4899e-01,  6.7364e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 6.6522e-02, -3.6841e-02, -2.3820e-01],\n",
       "          [ 2.1602e-02,  1.3765e-01,  9.4870e-03],\n",
       "          [-1.3090e-01, -2.0117e-01, -2.1677e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.0659e-01,  6.2209e-02,  3.4893e-02],\n",
       "          [ 1.4694e-01,  1.8613e-01, -2.1667e-02],\n",
       "          [ 1.6077e-01,  2.7391e-01,  8.1851e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.7705e-01,  3.1848e-01,  1.0092e-01],\n",
       "          [ 2.7513e-01, -2.7308e-01,  2.0595e-01],\n",
       "          [-1.5381e-01, -1.9864e-02, -3.0324e-01]]]], grad_fn=<CloneBackward>)), ('features.conv1.bias', tensor([ 0.0899,  0.0507, -0.0782, -0.1690, -0.2882,  0.2517, -0.2583, -0.0764,\n",
       "        -0.0736, -0.0721,  0.0182, -0.0322,  0.0293, -0.2790, -0.2696, -0.3073,\n",
       "         0.2384,  0.0212, -0.0347, -0.1500, -0.2425, -0.0683, -0.0535, -0.1270,\n",
       "         0.0841, -0.2656,  0.1925, -0.0413,  0.2163,  0.2532, -0.2341,  0.1484,\n",
       "         0.0272, -0.2992, -0.2951, -0.0554, -0.2142, -0.0491,  0.1129, -0.0183,\n",
       "        -0.1061,  0.2715,  0.2746, -0.0739,  0.0446, -0.1062,  0.2964,  0.0491,\n",
       "         0.1781,  0.0305, -0.0522,  0.2136, -0.2059, -0.0741,  0.2843, -0.0004,\n",
       "         0.3129,  0.0031,  0.1940,  0.0098,  0.1040, -0.3013,  0.1947, -0.1633],\n",
       "       grad_fn=<CloneBackward>)), ('features.bn1.weight', tensor([0.6982, 0.6375, 0.3329, 0.7467, 0.3255, 0.4384, 0.6465, 0.2276, 0.3996,\n",
       "        0.2202, 0.1898, 0.3228, 0.2346, 0.9019, 0.0983, 0.3745, 0.2895, 0.3253,\n",
       "        0.0318, 0.0191, 0.2182, 0.2754, 0.8890, 0.6304, 0.9511, 0.1695, 0.0183,\n",
       "        0.2345, 0.8358, 0.9978, 0.4638, 0.5600, 0.0835, 0.2921, 0.6897, 0.4141,\n",
       "        0.2116, 0.4424, 0.3548, 0.0189, 0.7917, 0.5266, 0.7723, 0.6386, 0.2016,\n",
       "        0.2242, 0.6579, 0.0478, 0.2280, 0.6628, 0.6005, 0.6724, 0.6659, 0.7232,\n",
       "        0.8436, 0.5121, 0.5594, 0.7774, 0.6240, 0.1343, 0.2477, 0.2767, 0.8069,\n",
       "        0.6123], grad_fn=<CloneBackward>)), ('features.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       grad_fn=<CloneBackward>)), ('features.conv2.weight', tensor([[[[-0.0130,  0.0363, -0.0042],\n",
       "          [ 0.0168,  0.0089, -0.0207],\n",
       "          [ 0.0023, -0.0351, -0.0281]],\n",
       "\n",
       "         [[ 0.0032, -0.0098, -0.0022],\n",
       "          [ 0.0185, -0.0406, -0.0129],\n",
       "          [-0.0170,  0.0377,  0.0414]],\n",
       "\n",
       "         [[-0.0372,  0.0237, -0.0361],\n",
       "          [ 0.0392, -0.0021, -0.0167],\n",
       "          [ 0.0252,  0.0367,  0.0031]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0226,  0.0205, -0.0207],\n",
       "          [-0.0006,  0.0108, -0.0359],\n",
       "          [ 0.0095,  0.0393,  0.0352]],\n",
       "\n",
       "         [[-0.0391, -0.0407,  0.0338],\n",
       "          [-0.0313,  0.0144, -0.0408],\n",
       "          [-0.0274,  0.0003, -0.0174]],\n",
       "\n",
       "         [[ 0.0052,  0.0287, -0.0409],\n",
       "          [-0.0387,  0.0237, -0.0051],\n",
       "          [-0.0183,  0.0178,  0.0103]]],\n",
       "\n",
       "\n",
       "        [[[-0.0300, -0.0382, -0.0396],\n",
       "          [-0.0158,  0.0025,  0.0031],\n",
       "          [ 0.0292,  0.0004, -0.0114]],\n",
       "\n",
       "         [[-0.0401, -0.0065, -0.0103],\n",
       "          [-0.0035,  0.0181, -0.0213],\n",
       "          [ 0.0050, -0.0415,  0.0393]],\n",
       "\n",
       "         [[ 0.0349,  0.0293, -0.0055],\n",
       "          [-0.0209, -0.0399, -0.0051],\n",
       "          [-0.0272,  0.0403, -0.0002]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0127, -0.0295,  0.0051],\n",
       "          [-0.0331, -0.0293,  0.0123],\n",
       "          [-0.0241,  0.0416,  0.0195]],\n",
       "\n",
       "         [[ 0.0130,  0.0170, -0.0367],\n",
       "          [-0.0099, -0.0389, -0.0380],\n",
       "          [-0.0029,  0.0199, -0.0190]],\n",
       "\n",
       "         [[ 0.0416, -0.0414,  0.0352],\n",
       "          [ 0.0371, -0.0102, -0.0130],\n",
       "          [ 0.0395,  0.0373, -0.0132]]],\n",
       "\n",
       "\n",
       "        [[[-0.0260, -0.0064,  0.0214],\n",
       "          [-0.0187,  0.0351, -0.0293],\n",
       "          [-0.0335,  0.0380,  0.0245]],\n",
       "\n",
       "         [[ 0.0404,  0.0379,  0.0219],\n",
       "          [-0.0005,  0.0118,  0.0031],\n",
       "          [-0.0282, -0.0011,  0.0259]],\n",
       "\n",
       "         [[ 0.0059,  0.0126,  0.0301],\n",
       "          [-0.0247, -0.0110,  0.0221],\n",
       "          [ 0.0034,  0.0197,  0.0032]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0055,  0.0333, -0.0076],\n",
       "          [-0.0082, -0.0399,  0.0215],\n",
       "          [-0.0047, -0.0276,  0.0242]],\n",
       "\n",
       "         [[-0.0011,  0.0348,  0.0279],\n",
       "          [ 0.0320, -0.0036, -0.0400],\n",
       "          [ 0.0081, -0.0214, -0.0193]],\n",
       "\n",
       "         [[-0.0129, -0.0222, -0.0084],\n",
       "          [-0.0207, -0.0186,  0.0085],\n",
       "          [ 0.0275,  0.0095, -0.0191]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0320,  0.0118, -0.0286],\n",
       "          [-0.0186,  0.0112,  0.0079],\n",
       "          [-0.0027, -0.0324, -0.0240]],\n",
       "\n",
       "         [[ 0.0378, -0.0274,  0.0149],\n",
       "          [-0.0110, -0.0091,  0.0103],\n",
       "          [ 0.0300,  0.0001, -0.0361]],\n",
       "\n",
       "         [[-0.0100,  0.0142, -0.0122],\n",
       "          [-0.0410,  0.0298, -0.0051],\n",
       "          [ 0.0009, -0.0381, -0.0342]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0263,  0.0245, -0.0100],\n",
       "          [ 0.0281,  0.0089, -0.0270],\n",
       "          [-0.0306, -0.0300, -0.0270]],\n",
       "\n",
       "         [[-0.0307,  0.0222, -0.0228],\n",
       "          [ 0.0235,  0.0188, -0.0273],\n",
       "          [-0.0125,  0.0268,  0.0017]],\n",
       "\n",
       "         [[-0.0358, -0.0216,  0.0013],\n",
       "          [ 0.0174, -0.0318, -0.0282],\n",
       "          [-0.0286, -0.0115, -0.0308]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0257, -0.0207, -0.0382],\n",
       "          [ 0.0363,  0.0171,  0.0364],\n",
       "          [ 0.0361,  0.0168,  0.0077]],\n",
       "\n",
       "         [[-0.0407, -0.0262,  0.0148],\n",
       "          [ 0.0200,  0.0011, -0.0411],\n",
       "          [ 0.0377, -0.0390, -0.0330]],\n",
       "\n",
       "         [[ 0.0349, -0.0076,  0.0065],\n",
       "          [ 0.0323,  0.0029,  0.0027],\n",
       "          [ 0.0248, -0.0237,  0.0207]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0397, -0.0334,  0.0238],\n",
       "          [ 0.0148,  0.0320,  0.0377],\n",
       "          [ 0.0034, -0.0374, -0.0201]],\n",
       "\n",
       "         [[ 0.0274,  0.0147, -0.0398],\n",
       "          [ 0.0064,  0.0168,  0.0144],\n",
       "          [-0.0141,  0.0066, -0.0098]],\n",
       "\n",
       "         [[ 0.0120,  0.0213, -0.0056],\n",
       "          [ 0.0202,  0.0278, -0.0134],\n",
       "          [-0.0356,  0.0200,  0.0358]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0040,  0.0122,  0.0027],\n",
       "          [-0.0348,  0.0010, -0.0208],\n",
       "          [-0.0333,  0.0386, -0.0163]],\n",
       "\n",
       "         [[-0.0115, -0.0401,  0.0195],\n",
       "          [ 0.0214,  0.0113, -0.0213],\n",
       "          [ 0.0391,  0.0003, -0.0276]],\n",
       "\n",
       "         [[-0.0289,  0.0108,  0.0228],\n",
       "          [-0.0032,  0.0217,  0.0357],\n",
       "          [ 0.0105, -0.0289, -0.0275]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0061,  0.0166,  0.0377],\n",
       "          [-0.0298,  0.0219, -0.0115],\n",
       "          [ 0.0157,  0.0327,  0.0281]],\n",
       "\n",
       "         [[ 0.0101, -0.0254, -0.0039],\n",
       "          [ 0.0334, -0.0230,  0.0197],\n",
       "          [ 0.0342,  0.0391,  0.0340]],\n",
       "\n",
       "         [[ 0.0122, -0.0108, -0.0246],\n",
       "          [ 0.0378, -0.0020,  0.0223],\n",
       "          [-0.0023,  0.0207,  0.0342]]]], grad_fn=<CloneBackward>)), ('features.conv2.bias', tensor([-0.0278,  0.0152,  0.0088,  0.0076, -0.0215, -0.0050,  0.0226, -0.0017,\n",
       "        -0.0354, -0.0357,  0.0116, -0.0133, -0.0182,  0.0220, -0.0308, -0.0397,\n",
       "        -0.0289, -0.0111, -0.0245,  0.0297,  0.0213, -0.0313, -0.0210, -0.0181,\n",
       "         0.0130,  0.0416,  0.0160,  0.0098,  0.0287, -0.0257,  0.0225,  0.0023,\n",
       "         0.0022,  0.0189, -0.0329,  0.0211,  0.0029,  0.0241,  0.0239,  0.0190,\n",
       "        -0.0212,  0.0364,  0.0411, -0.0417,  0.0371, -0.0289,  0.0193, -0.0129,\n",
       "         0.0024, -0.0368,  0.0264,  0.0145,  0.0221, -0.0350,  0.0191,  0.0015,\n",
       "        -0.0114,  0.0206,  0.0242,  0.0175, -0.0034, -0.0177, -0.0285,  0.0112],\n",
       "       grad_fn=<CloneBackward>)), ('features.bn2.weight', tensor([0.0978, 0.8158, 0.2650, 0.1968, 0.8132, 0.7244, 0.3902, 0.4539, 0.1474,\n",
       "        0.6478, 0.4669, 0.8806, 0.9630, 0.2123, 0.2354, 0.5022, 0.6939, 0.0399,\n",
       "        0.7175, 0.8386, 0.4766, 0.9133, 0.8717, 0.3504, 0.2156, 0.1351, 0.1273,\n",
       "        0.8069, 0.4631, 0.5751, 0.8606, 0.1844, 0.9914, 0.5906, 0.8693, 0.1625,\n",
       "        0.1732, 0.9177, 0.6386, 0.6017, 0.5011, 0.5333, 0.3780, 0.0785, 0.4844,\n",
       "        0.0654, 0.0713, 0.8116, 0.3916, 0.4081, 0.3419, 0.8921, 0.5254, 0.2379,\n",
       "        0.1955, 0.0432, 0.1075, 0.6585, 0.6384, 0.5262, 0.2597, 0.5312, 0.5360,\n",
       "        0.3270], grad_fn=<CloneBackward>)), ('features.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       grad_fn=<CloneBackward>)), ('features.conv3.weight', tensor([[[[-3.2427e-02, -2.5656e-02,  2.3543e-02],\n",
       "          [-2.9180e-02,  3.3374e-03,  1.3070e-02],\n",
       "          [-4.1547e-02, -3.9488e-02,  2.9841e-02]],\n",
       "\n",
       "         [[-2.5536e-02,  4.0381e-02, -2.4869e-02],\n",
       "          [ 1.8815e-02,  1.3836e-02, -3.0915e-02],\n",
       "          [ 2.3917e-02,  3.2516e-02,  3.9471e-02]],\n",
       "\n",
       "         [[-3.3998e-02,  2.9386e-02, -1.8287e-02],\n",
       "          [-2.9685e-03, -1.6066e-02,  1.7344e-02],\n",
       "          [ 9.3686e-03,  3.6282e-02,  1.1014e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.0739e-02, -2.4947e-02,  1.3525e-02],\n",
       "          [-1.5668e-02,  1.1070e-02, -2.2116e-02],\n",
       "          [-1.7611e-02, -2.5645e-02,  2.9328e-02]],\n",
       "\n",
       "         [[-3.7357e-02,  1.9776e-02,  2.1376e-02],\n",
       "          [-2.2506e-02, -4.1345e-02, -3.5598e-02],\n",
       "          [ 2.3481e-02, -3.8778e-02, -3.9479e-02]],\n",
       "\n",
       "         [[ 3.0839e-02,  2.6462e-02, -3.9669e-02],\n",
       "          [-2.8227e-02, -2.3345e-02,  3.3547e-02],\n",
       "          [-3.4016e-02,  1.1669e-02,  8.6124e-04]]],\n",
       "\n",
       "\n",
       "        [[[-3.5436e-02,  9.2653e-03,  2.3578e-02],\n",
       "          [-1.1689e-02,  3.8797e-03, -1.7672e-02],\n",
       "          [ 1.0861e-03,  1.5437e-02, -1.2176e-02]],\n",
       "\n",
       "         [[ 2.9635e-02,  3.2387e-03, -4.4620e-03],\n",
       "          [-1.1618e-02,  3.9223e-02,  4.0398e-02],\n",
       "          [-2.3916e-02,  3.4547e-02, -7.1994e-03]],\n",
       "\n",
       "         [[ 4.0802e-02, -7.4381e-03, -8.4392e-03],\n",
       "          [ 2.9054e-02, -1.7901e-02, -2.9488e-02],\n",
       "          [-1.0242e-02, -1.8972e-02,  1.4508e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.9378e-02,  3.4769e-02,  2.3636e-02],\n",
       "          [-3.2452e-02, -9.4816e-03,  2.9582e-02],\n",
       "          [ 3.5816e-02, -2.6352e-03,  9.8730e-03]],\n",
       "\n",
       "         [[-1.9615e-02, -1.5446e-02,  7.7801e-03],\n",
       "          [-2.6655e-02,  1.4050e-02, -1.8495e-02],\n",
       "          [ 2.6021e-02,  3.9952e-02, -3.1646e-02]],\n",
       "\n",
       "         [[ 3.6165e-02, -2.7755e-02,  8.6317e-03],\n",
       "          [ 3.2892e-02,  4.0851e-02,  1.8647e-03],\n",
       "          [ 1.6926e-02,  5.6931e-03, -9.9183e-03]]],\n",
       "\n",
       "\n",
       "        [[[-2.9153e-02,  1.1222e-02,  3.5782e-02],\n",
       "          [-3.9189e-02, -4.1281e-02, -2.8683e-02],\n",
       "          [ 2.1050e-02,  2.8494e-02, -2.8853e-02]],\n",
       "\n",
       "         [[-2.4005e-02, -3.2241e-02,  9.5249e-03],\n",
       "          [ 1.9821e-02, -3.0194e-02, -4.1240e-02],\n",
       "          [-1.3161e-02,  8.9709e-03,  1.0424e-02]],\n",
       "\n",
       "         [[-2.8677e-02, -8.4116e-03, -2.4566e-02],\n",
       "          [-1.8973e-02, -4.0501e-02, -2.6735e-03],\n",
       "          [-2.0932e-02, -1.7012e-03,  4.0665e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.5645e-02, -1.5130e-02,  1.6669e-02],\n",
       "          [-2.5688e-02, -3.9143e-02, -3.2533e-02],\n",
       "          [-3.8713e-02,  3.1537e-02, -3.1544e-02]],\n",
       "\n",
       "         [[-3.1895e-02,  2.1145e-03,  1.1041e-02],\n",
       "          [ 4.0536e-02, -3.6209e-02,  3.5161e-02],\n",
       "          [ 2.0571e-02,  2.9659e-02,  6.2102e-03]],\n",
       "\n",
       "         [[-3.8973e-02, -8.7100e-03,  3.9577e-02],\n",
       "          [-2.1251e-02,  2.1324e-02,  8.7069e-03],\n",
       "          [-7.2928e-03, -2.6461e-02, -4.0386e-02]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.0568e-02, -2.0623e-02, -4.1276e-02],\n",
       "          [ 2.1856e-02, -2.3624e-02, -1.1486e-02],\n",
       "          [-3.3172e-02,  9.6587e-03,  6.6622e-03]],\n",
       "\n",
       "         [[-1.3452e-02, -3.8756e-02,  3.5332e-02],\n",
       "          [ 1.3796e-02,  3.8010e-02, -7.5744e-03],\n",
       "          [-2.0450e-02, -3.0653e-02,  3.4297e-02]],\n",
       "\n",
       "         [[-2.2635e-02, -1.1953e-02, -2.6365e-02],\n",
       "          [-2.4008e-02, -3.3582e-02,  2.8460e-02],\n",
       "          [-1.9457e-02,  1.7204e-02,  1.2802e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9134e-02, -2.0726e-02, -2.7004e-02],\n",
       "          [ 5.3172e-03, -1.1014e-03, -3.2828e-02],\n",
       "          [ 1.5795e-02, -1.0875e-02, -2.2756e-02]],\n",
       "\n",
       "         [[-5.8243e-03, -9.2174e-03,  8.5622e-03],\n",
       "          [-3.6112e-02, -8.1241e-03, -1.8991e-02],\n",
       "          [ 2.0626e-02, -1.2135e-02,  3.6191e-02]],\n",
       "\n",
       "         [[ 2.5137e-02, -2.0581e-02,  1.7079e-02],\n",
       "          [ 2.2579e-02,  2.6709e-02, -6.5927e-03],\n",
       "          [ 2.3317e-02,  6.6358e-03,  8.5952e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.6816e-02, -2.8769e-02,  2.6426e-02],\n",
       "          [ 6.3933e-03,  3.4745e-02, -5.3216e-03],\n",
       "          [ 1.3235e-02, -5.9389e-03,  2.8185e-02]],\n",
       "\n",
       "         [[-1.1891e-02,  4.0013e-02, -9.2943e-03],\n",
       "          [ 1.6283e-02, -3.1457e-02, -4.3971e-03],\n",
       "          [-4.1431e-02,  2.6374e-02, -3.5776e-02]],\n",
       "\n",
       "         [[ 1.0622e-02,  2.9528e-02, -2.8861e-02],\n",
       "          [ 2.9193e-02, -4.0053e-02, -1.4846e-02],\n",
       "          [ 2.6955e-03,  9.2096e-03, -1.2256e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.5018e-03, -2.1345e-02,  2.6936e-02],\n",
       "          [ 1.6902e-02, -6.0368e-05,  2.3382e-02],\n",
       "          [-1.8792e-02, -2.0039e-02,  1.0439e-02]],\n",
       "\n",
       "         [[-1.4893e-02,  1.4719e-02,  3.8570e-03],\n",
       "          [ 3.3486e-03, -1.4629e-02,  1.5128e-02],\n",
       "          [ 3.0593e-02,  1.8648e-02, -1.8732e-02]],\n",
       "\n",
       "         [[-2.7297e-02,  3.0437e-02, -2.3435e-02],\n",
       "          [ 2.0480e-02, -3.5585e-02, -3.3455e-02],\n",
       "          [-1.4854e-03, -3.3639e-02, -3.3794e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.5174e-02,  8.5490e-03, -1.2323e-02],\n",
       "          [ 2.0669e-02, -3.0116e-02, -5.9842e-03],\n",
       "          [ 3.4862e-02,  2.6854e-02,  3.5678e-02]],\n",
       "\n",
       "         [[-7.4043e-03,  4.9456e-03, -9.9595e-03],\n",
       "          [-3.7400e-03, -1.6249e-02, -3.5140e-02],\n",
       "          [ 2.5084e-02,  2.5079e-02,  4.0109e-02]],\n",
       "\n",
       "         [[ 1.6277e-02,  1.3413e-02,  9.2732e-04],\n",
       "          [-2.8328e-02, -4.1570e-02, -2.3975e-02],\n",
       "          [ 1.9192e-02,  2.8475e-02, -2.5891e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.7772e-02,  3.3041e-02,  3.8138e-02],\n",
       "          [-1.8397e-03,  4.0428e-02, -2.9087e-03],\n",
       "          [-3.3495e-03,  1.2920e-02,  2.4854e-02]],\n",
       "\n",
       "         [[ 3.3486e-02,  2.0107e-02,  2.6765e-02],\n",
       "          [-3.0747e-02, -2.1369e-02, -3.9857e-02],\n",
       "          [-1.6215e-02,  1.4522e-02, -2.0163e-02]],\n",
       "\n",
       "         [[-3.2599e-02,  1.0520e-02, -1.0591e-02],\n",
       "          [ 2.1557e-02, -1.1457e-03,  1.4254e-02],\n",
       "          [ 2.5567e-02, -1.1716e-02,  3.5229e-02]]]], grad_fn=<CloneBackward>)), ('features.conv3.bias', tensor([ 0.0407,  0.0345,  0.0275,  0.0363,  0.0066, -0.0102,  0.0261, -0.0282,\n",
       "         0.0050, -0.0065,  0.0372,  0.0186, -0.0074, -0.0177, -0.0276, -0.0343,\n",
       "        -0.0389, -0.0311,  0.0369,  0.0107,  0.0161,  0.0142, -0.0069,  0.0149,\n",
       "         0.0260, -0.0113, -0.0161, -0.0360,  0.0015, -0.0201, -0.0148,  0.0189,\n",
       "         0.0158, -0.0129, -0.0361, -0.0245,  0.0071, -0.0085,  0.0250,  0.0202,\n",
       "        -0.0108, -0.0278, -0.0268,  0.0129,  0.0188, -0.0243, -0.0004,  0.0249,\n",
       "        -0.0048, -0.0309,  0.0361,  0.0155,  0.0138,  0.0094,  0.0352,  0.0214,\n",
       "         0.0402,  0.0025, -0.0231,  0.0367, -0.0035, -0.0229,  0.0023, -0.0122],\n",
       "       grad_fn=<CloneBackward>)), ('features.bn3.weight', tensor([0.8127, 0.7668, 0.9740, 0.5409, 0.1071, 0.1449, 0.8754, 0.2890, 0.7674,\n",
       "        0.2709, 0.9531, 0.8499, 0.5113, 0.7222, 0.7240, 0.2556, 0.0077, 0.8027,\n",
       "        0.3006, 0.1352, 0.4788, 0.8285, 0.5273, 0.7234, 0.4353, 0.3076, 0.4963,\n",
       "        0.9066, 0.1663, 0.5731, 0.1793, 0.3897, 0.4454, 0.3945, 0.1473, 0.3187,\n",
       "        0.2660, 0.3913, 0.7822, 0.3013, 0.7869, 0.1100, 0.6719, 0.3380, 0.3511,\n",
       "        0.6490, 0.0999, 0.9880, 0.2826, 0.1263, 0.3357, 0.9700, 0.7869, 0.5361,\n",
       "        0.2620, 0.6908, 0.8747, 0.3693, 0.9693, 0.3660, 0.5824, 0.2542, 0.8417,\n",
       "        0.7737], grad_fn=<CloneBackward>)), ('features.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       grad_fn=<CloneBackward>)), ('fc.weight', tensor([[-0.0090, -0.0739,  0.0433, -0.0672, -0.0423, -0.0518,  0.0071, -0.0511,\n",
       "          0.0851, -0.0468,  0.0739, -0.0903,  0.0925, -0.0628,  0.0191, -0.1044,\n",
       "          0.0843,  0.1247, -0.1248, -0.0441, -0.0973, -0.0941, -0.0428,  0.0590,\n",
       "          0.1046,  0.1162,  0.0177,  0.0274, -0.1173,  0.0761,  0.0710,  0.0667,\n",
       "          0.0811, -0.1108, -0.0494,  0.0134, -0.0534, -0.0645, -0.0004,  0.0607,\n",
       "         -0.0963, -0.0577,  0.0868, -0.0262,  0.1153,  0.0373,  0.0240, -0.0019,\n",
       "         -0.1130, -0.0695,  0.0687, -0.0388,  0.0029, -0.1043, -0.0032,  0.0683,\n",
       "         -0.0861,  0.1160, -0.1143,  0.0143, -0.0591, -0.1105, -0.0330, -0.1154],\n",
       "        [ 0.0893,  0.0218, -0.1078,  0.0933, -0.0827, -0.0385, -0.0303,  0.0130,\n",
       "         -0.0279, -0.0457, -0.0269, -0.0734,  0.0457,  0.0626, -0.1041, -0.0346,\n",
       "          0.0116,  0.0250, -0.0572,  0.0079, -0.1135, -0.1006,  0.0565, -0.0587,\n",
       "          0.0164, -0.0139,  0.0603, -0.0927, -0.0121,  0.0295,  0.1059, -0.0551,\n",
       "          0.1215, -0.0291, -0.1103, -0.1206, -0.0827,  0.0951, -0.0949,  0.0578,\n",
       "          0.0085, -0.0617,  0.0530,  0.0258, -0.0041, -0.1140, -0.0265,  0.0433,\n",
       "         -0.0152, -0.0295, -0.0283, -0.1112, -0.1031, -0.1106,  0.0929, -0.1248,\n",
       "          0.0575,  0.1185,  0.0440, -0.0597,  0.0069, -0.0541,  0.1230,  0.0702],\n",
       "        [-0.1153,  0.0180,  0.0037, -0.0425, -0.0235, -0.0992, -0.0336,  0.0178,\n",
       "          0.1017, -0.0100,  0.0786,  0.0723,  0.0117,  0.0972, -0.0731, -0.0264,\n",
       "         -0.0566,  0.0424, -0.1043, -0.0246,  0.0211,  0.1184, -0.0958, -0.0357,\n",
       "          0.0763,  0.0739,  0.0122, -0.0406,  0.0640,  0.0646,  0.0851,  0.1193,\n",
       "          0.0921, -0.1071,  0.0959, -0.0286,  0.0598, -0.0341,  0.0291, -0.0046,\n",
       "         -0.1042,  0.0203,  0.0658,  0.0181,  0.0877, -0.0320,  0.1152, -0.0317,\n",
       "          0.0093, -0.0094,  0.0890, -0.0437,  0.0945,  0.0371, -0.0058,  0.0869,\n",
       "         -0.0233, -0.0388, -0.1045, -0.1244,  0.0744, -0.1012, -0.0967, -0.0570],\n",
       "        [-0.0466, -0.1168,  0.0315,  0.0005,  0.0767,  0.1225,  0.0350, -0.0054,\n",
       "         -0.0748, -0.0073, -0.0110, -0.0244,  0.0351,  0.0678, -0.0297,  0.1013,\n",
       "         -0.0606,  0.0118,  0.0992,  0.0350,  0.0028,  0.0070,  0.0771, -0.0086,\n",
       "         -0.0140, -0.0720,  0.0351,  0.0187,  0.0354,  0.0153,  0.1182,  0.0136,\n",
       "         -0.0172, -0.0308,  0.0527, -0.0003,  0.0851, -0.1035, -0.0082, -0.0562,\n",
       "          0.0616, -0.0145,  0.0591,  0.1008,  0.0171, -0.1089,  0.1105,  0.1219,\n",
       "         -0.0261,  0.0647,  0.0147, -0.0645, -0.0678,  0.0663,  0.0634,  0.0518,\n",
       "         -0.1117,  0.0438,  0.0482,  0.0859, -0.0768, -0.1175, -0.0923,  0.0356],\n",
       "        [ 0.1098,  0.0421, -0.0302,  0.0667,  0.0375,  0.0526,  0.0884, -0.0684,\n",
       "          0.1187,  0.0939, -0.0903,  0.1152,  0.1094, -0.0790, -0.0859, -0.0031,\n",
       "         -0.0649, -0.0679,  0.0180, -0.0757, -0.0925,  0.0278,  0.0811, -0.1016,\n",
       "          0.0650, -0.1018, -0.1145,  0.0659, -0.0851,  0.0140, -0.0999, -0.0891,\n",
       "         -0.0054, -0.1220, -0.0952, -0.0666, -0.1055,  0.0889, -0.1239, -0.0054,\n",
       "          0.0887, -0.0952, -0.0514, -0.0003,  0.0477,  0.0728,  0.0450, -0.1036,\n",
       "         -0.0404,  0.0969, -0.0343, -0.0858, -0.1034, -0.0994, -0.0896,  0.0924,\n",
       "          0.0428, -0.0798,  0.0793, -0.0173,  0.0189,  0.0111, -0.0991, -0.1095]],\n",
       "       grad_fn=<CloneBackward>)), ('fc.bias', tensor([-0.0351, -0.0600,  0.1078,  0.0130,  0.0041], grad_fn=<CloneBackward>))])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=[w.clone() for w in list(weights.values())]\n",
    "l=[]\n",
    "for s,t in zip(weights.keys(),temp):\n",
    "    l.append((s,t))\n",
    "dic=OrderedDict((s,t) for (s,t) in l)\n",
    "dic.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
