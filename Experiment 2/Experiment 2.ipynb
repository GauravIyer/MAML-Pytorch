{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp2(Current).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfns8i2cRcXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVienGSqRveV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/gdrive/My Drive/\"\n",
        "%cd \"/content/gdrive/My Drive/Experiment2/Data\"\n",
        "!unzip \"/content/gdrive/My Drive/Experiment2/Data/images_background.zip\"\n",
        "!unzip \"/content/gdrive/My Drive/Experiment2/Data/images_evaluation.zip\"\n",
        "%cd \"/content/gdrive/My Drive/Experiment2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x-ptFgFRxKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPvDDv4zR1rZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainframe=pd.read_csv(\"train_data.csv\")\n",
        "testframe=pd.read_csv(\"test_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-fzPFb8SEqm",
        "colab_type": "code",
        "outputId": "4ec84cf5-0ea0-4b96-c93c-6738efcefbb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bezMspDESlUx",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "class Task(object):\n",
        "  def __init__(self,all_classes,num_classes,num_instances):\n",
        "    self.all_classes=all_classes\n",
        "    self.num_classes=num_classes\n",
        "    self.num_instances=num_instances\n",
        "    self.train_roots=[]\n",
        "    self.meta_roots=[]\n",
        "    self.train_labels=[]\n",
        "    self.meta_labels=[]\n",
        "    samples_per_class=20\n",
        "    sampled_classes=random.sample(all_classes,num_classes)\n",
        "    label=0\n",
        "    #labels=list(range(len(sampled_classes)))\n",
        "\n",
        "    for c in sampled_classes:\n",
        "      cframe=trainframe.iloc[(c*samples_per_class):((c+1)*samples_per_class)]\n",
        "      cframe.reset_index(inplace=True,drop=True)\n",
        "      paths=cframe[\"Path\"]\n",
        "      sample_idxs=np.random.choice(samples_per_class,samples_per_class,replace=False)\n",
        "      train_idxs=sample_idxs[:num_instances]\n",
        "      meta_idxs=sample_idxs[num_instances:(num_instances*2)]\n",
        "      for idx in train_idxs:\n",
        "        self.train_roots.append(paths[idx])\n",
        "        self.train_labels.append(label)\n",
        "      for idx in meta_idxs:\n",
        "        self.meta_roots.append(paths[idx])\n",
        "        self.meta_labels.append(label)\n",
        "      label+=1\n",
        "\n",
        "class TestTask(object):\n",
        "  def __init__(self,all_classes,num_classes,num_instances,num_test_instances):\n",
        "    self.all_classes=all_classes\n",
        "    self.num_classes=num_classes\n",
        "    self.num_instances=num_instances\n",
        "    self.num_test_instances=num_test_instances\n",
        "    self.test_roots=[]\n",
        "    self.train_roots=[]\n",
        "    self.test_labels=[]\n",
        "    self.train_labels=[]\n",
        "    samples_per_class=20\n",
        "    sampled_classes=random.sample(all_classes,num_classes)\n",
        "    label=0\n",
        "    #labels=list(range(len(sampled_classes)))\n",
        "\n",
        "    for c in sampled_classes:\n",
        "      cframe=testframe.iloc[((c-964)*samples_per_class):(((c+1)-964)*samples_per_class)]\n",
        "      cframe.reset_index(inplace=True,drop=True)\n",
        "      paths=cframe[\"Path\"]\n",
        "      sample_idxs=np.random.choice(samples_per_class,samples_per_class,replace=False)\n",
        "      train_idxs=sample_idxs[:num_instances]\n",
        "      test_idxs=sample_idxs[num_instances:(num_instances+num_test_instances)]\n",
        "      for idx in test_idxs:\n",
        "        self.test_roots.append(paths[idx])\n",
        "        self.test_labels.append(label)\n",
        "      # for idx in meta_idxs:\n",
        "      #   self.meta_roots.append(paths[idx])\n",
        "      #   self.meta_labels.append(label)\n",
        "      for idx in train_idxs:\n",
        "        self.train_roots.append(paths[idx])\n",
        "        self.train_labels.append(label)\n",
        "      label+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxeqqXaFdgC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MiniSet(Dataset):\n",
        "  def __init__(self,fileroots,labels,transform):\n",
        "    self.fileroots=fileroots\n",
        "    self.labels=labels\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.fileroots)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img=Image.open(self.fileroots[idx])\n",
        "    img=self.transform(img)\n",
        "    return img,self.labels[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YOsePJ8fnBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform=transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor()])\n",
        "def get_loaders(task):\n",
        "  loaders={}\n",
        "  train_fileroots=task.train_roots\n",
        "  train_labels=task.train_labels\n",
        "  meta_fileroots=task.meta_roots\n",
        "  meta_labels=task.meta_labels\n",
        "  trainloader=DataLoader(MiniSet(train_fileroots,train_labels,transform),\n",
        "                         batch_size=len(train_fileroots),shuffle=True)\n",
        "  metaloader=DataLoader(MiniSet(meta_fileroots,meta_labels,transform),\n",
        "                         batch_size=len(meta_fileroots),shuffle=True)\n",
        "  loaders[\"train\"]=trainloader\n",
        "  loaders[\"meta\"]=metaloader\n",
        "  return loaders\n",
        "\n",
        "def get_test_loaders(task):\n",
        "  loaders={}\n",
        "  test_fileroots=task.test_roots\n",
        "  test_labels=task.test_labels\n",
        "  train_fileroots=task.train_roots\n",
        "  train_labels=task.train_labels\n",
        "  testloader=DataLoader(MiniSet(test_fileroots,test_labels,transform),\n",
        "                         batch_size=len(test_fileroots),shuffle=True)\n",
        "  # metaloader=DataLoader(MiniSet(meta_fileroots,meta_labels,transform),\n",
        "  #                        batch_size=len(meta_fileroots),shuffle=True)\n",
        "  trainloader=DataLoader(MiniSet(train_fileroots,train_labels,transform),\n",
        "                         batch_size=len(train_fileroots),shuffle=True)\n",
        "  loaders[\"train\"]=trainloader\n",
        "  #loaders[\"meta\"]=metaloader\n",
        "  loaders[\"test\"]=testloader\n",
        "  return loaders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a8pIAD-jEd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseNet(nn.Module):\n",
        "  def __init__(self,num_classes):\n",
        "    super(BaseNet,self).__init__()\n",
        "    self.features = nn.Sequential(OrderedDict([\n",
        "                ('conv1', nn.Conv2d(1, 64, 3)),\n",
        "                ('bn1', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
        "                ('relu1', nn.ReLU(inplace=True)),\n",
        "                ('pool1', nn.MaxPool2d(2,2)),\n",
        "                ('conv2', nn.Conv2d(64,64,3)),\n",
        "                ('bn2', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
        "                ('relu2', nn.ReLU(inplace=True)),\n",
        "                ('pool2', nn.MaxPool2d(2,2)),\n",
        "                ('conv3', nn.Conv2d(64,64,3)),\n",
        "                ('bn3', nn.BatchNorm2d(64, momentum=1, affine=True)),\n",
        "                ('relu3', nn.ReLU(inplace=True)),\n",
        "                ('pool3', nn.MaxPool2d(2,2))]))    \n",
        "    self.add_module('fc', nn.Linear(64,num_classes))\n",
        "\n",
        "  def forward(self,x,weights=None):\n",
        "    if weights==None:  \n",
        "      output=self.features(x)\n",
        "      output=output.view(-1,64)\n",
        "      output=self.fc(output)\n",
        "    else:\n",
        "      x = F.conv2d(x, weights['meta_learner.features.conv1.weight'], weights['meta_learner.features.conv1.bias'])\n",
        "      x = F.batch_norm(x, weights['meta_learner.features.bn1.running_mean'], \n",
        "                         weights['meta_learner.features.bn1.running_var'],\n",
        "                          weights['meta_learner.features.bn1.weight'],\n",
        "                         weights['meta_learner.features.bn1.bias'],momentum=1,training=True)\n",
        "      x = F.relu(x)\n",
        "      x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
        "      x = F.conv2d(x, weights['meta_learner.features.conv2.weight'], weights['meta_learner.features.conv2.bias'])\n",
        "      x = F.batch_norm(x, weights['meta_learner.features.bn2.running_mean'], \n",
        "                         weights['meta_learner.features.bn2.running_var'],\n",
        "                          weights['meta_learner.features.bn2.weight'],\n",
        "                         weights['meta_learner.features.bn2.bias'],momentum=1,training=True)\n",
        "      x = F.relu(x)\n",
        "      x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
        "      x = F.conv2d(x, weights['meta_learner.features.conv3.weight'], weights['meta_learner.features.conv3.bias'])\n",
        "      x = F.batch_norm(x, weights['meta_learner.features.bn3.running_mean'], \n",
        "                         weights['meta_learner.features.bn3.running_var'],\n",
        "                          weights['meta_learner.features.bn3.weight'],\n",
        "                         weights['meta_learner.features.bn3.bias'],momentum=1,training=True)\n",
        "      x = F.relu(x)\n",
        "      x = F.max_pool2d(x, kernel_size=2, stride=2) \n",
        "      x = x.view(x.size(0), 64)\n",
        "      output = F.linear(x, weights['meta_learner.fc.weight'], weights['meta_learner.fc.bias'])\n",
        "    out = F.log_softmax(output, dim=1)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oMtCHPGpBvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MetaLearner(nn.Module):\n",
        "  def __init__(self,num_classes):\n",
        "    super(MetaLearner, self).__init__()\n",
        "    #self.params=params\n",
        "    self.meta_learner=BaseNet(num_classes)\n",
        "\n",
        "  def forward(self,x,mod_weights=None):\n",
        "    if mod_weights==None:\n",
        "      out=self.meta_learner(x)\n",
        "    else:\n",
        "      out=self.meta_learner(x,mod_weights)\n",
        "    return out\n",
        "  \n",
        "  def clone_state_dict(self):\n",
        "    cloned_state_dict = {key: val.clone()for key, val in self.state_dict().items()}\n",
        "    return cloned_state_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx7EoKIdse91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_single_task(net,lr,loaders,num_updates,loss_metric):\n",
        "  net.train()\n",
        "  trainloader=loaders[\"train\"]\n",
        "  x,y=trainloader.__iter__().next()\n",
        "  x.to(device)\n",
        "  y.to(device)\n",
        "  output=net(x)\n",
        "  loss=loss_metric(output,y)\n",
        "\n",
        "  def zero_grad(params):\n",
        "    for p in params:\n",
        "      if p.grad is not None:\n",
        "        p.grad.zero_()\n",
        "  zero_grad(net.parameters())\n",
        "  grads=torch.autograd.grad(loss,net.parameters(),create_graph=True)\n",
        "  mod_state_dict=net.clone_state_dict()\n",
        "  mod_weights=OrderedDict()\n",
        "  for (k,v),g in zip(net.named_parameters(),grads):\n",
        "    mod_weights[k]=v-lr*g\n",
        "    mod_state_dict[k]=mod_weights[k]\n",
        "  for i in range(1,num_updates):\n",
        "    output=net(x,mod_state_dict)\n",
        "    loss=loss_metric(output,y)\n",
        "    zero_grad(mod_weights.values())\n",
        "    grads=torch.autograd.grad(loss,mod_weights.values(),create_graph=True)\n",
        "    for (k,v),g in zip(mod_weights.items(),grads):\n",
        "      mod_weights[k]=v-lr*g\n",
        "      mod_state_dict[k]=mod_weights[k]\n",
        "\n",
        "  return mod_state_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkFYZtD231Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net,meta_train_classes,meta_optimiser,loss_metric,num_classes,num_instances,num_tasks,lr,meta_lr,num_inner_updates,num_epochs):\n",
        "  total_loss=0  \n",
        "  print_every=100\n",
        "  plot_every=2\n",
        "  meta_losses=[]\n",
        "  for epoch in range(1,num_epochs+1):\n",
        "    state_dicts=[]\n",
        "    loaders_list=[]\n",
        "    for n in range(num_tasks):\n",
        "      task=Task(meta_train_classes,num_classes,num_instances)\n",
        "      loaders=get_loaders(task)\n",
        "      d=train_single_task(net,lr,loaders,num_inner_updates,loss_metric)\n",
        "      state_dicts.append(d)\n",
        "      loaders_list.append(loaders)\n",
        "    metaloss=0\n",
        "    for n in range(num_tasks):\n",
        "      loaders=loaders_list[n]\n",
        "      metaloader=loaders[\"meta\"]\n",
        "      x,y=metaloader.__iter__().next()\n",
        "      x.to(device)\n",
        "      y.to(device)\n",
        "      d=state_dicts[n]\n",
        "      output=net(x,d)\n",
        "      loss=loss_metric(output,y)\n",
        "      metaloss+=loss\n",
        "    metaloss/=float(num_tasks)\n",
        "    total_loss+=metaloss.item()\n",
        "    meta_optimiser.zero_grad()\n",
        "    metaloss.backward()\n",
        "    meta_optimiser.step()\n",
        "    if epoch % print_every == 0:\n",
        "      print(\"{}/{}. loss: {}\".format(epoch, num_epochs, total_loss / plot_every))\n",
        "    if epoch%plot_every==0:\n",
        "      meta_losses.append(total_loss/plot_every)\n",
        "      total_loss = 0\n",
        "    if (epoch%20)==0:\n",
        "      print(\"Epoch \"+str(epoch)+\" completed.\")\n",
        "  return meta_losses,net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_ATo_NuRlXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_metric=nn.NLLLoss()\n",
        "num_classes=5\n",
        "net=MetaLearner(num_classes)\n",
        "lr=1e-1\n",
        "meta_lr=1e-3\n",
        "meta_optimizer = torch.optim.Adam(net.parameters(), lr=meta_lr)\n",
        "num_instances=3\n",
        "num_tasks=10\n",
        "num_inner_updates=1\n",
        "num_epochs=1000\n",
        "train_classes=np.max(trainframe['Label'])\n",
        "train_classes=list(np.arange(train_classes))\n",
        "metalosses,net=train(net,train_classes,meta_optimizer,loss_metric,num_classes,num_instances,num_tasks,lr,meta_lr,num_inner_updates,num_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYRDRdTQVnzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(metalosses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5DfWZt_M8AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "  outputs = np.argmax(outputs, axis=1)\n",
        "  return np.sum(outputs == labels) / float(labels.size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BKPHC0QVzUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(net,test_classes,task_lr,num_classes=5,num_steps=100,num_eval_updates=3):\n",
        "  #net.eval()\n",
        "  losses=[]\n",
        "  acc_list=[]\n",
        "  for step in np.arange(num_steps):\n",
        "    task=TestTask(test_classes,num_classes=5,num_instances=3,num_test_instances=10)\n",
        "    loaders=get_test_loaders(task)\n",
        "    trainloader,testloader=loaders[\"train\"],loaders[\"test\"]\n",
        "    x_train,y_train=trainloader.__iter__().next()\n",
        "    x_test,y_test=testloader.__iter__().next()\n",
        "    x_train.to(device)\n",
        "    y_train.to(device)\n",
        "    x_test.to(device)\n",
        "    y_test.to(device)\n",
        "    #def __init__(self,all_classes,num_classes,num_instances,num_test_instances)\n",
        "    cloned_net=copy.deepcopy(net)\n",
        "    optim = torch.optim.SGD(cloned_net.parameters(),lr=task_lr)\n",
        "    for _ in range(num_eval_updates):\n",
        "      y_train_pred=cloned_net(x_train)\n",
        "      loss=loss_metric(y_train_pred,y_train)\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "    y_test_pred=cloned_net(x_test)\n",
        "    loss=loss_metric(y_test_pred,y_test)\n",
        "    losses.append(loss)\n",
        "    y_test_pred=y_test_pred.data.cpu().numpy()\n",
        "    y_test=y_test.data.cpu().numpy()\n",
        "    #print(y_test)\n",
        "    #print(y_test_pred)\n",
        "    acc=accuracy(y_test_pred,y_test)\n",
        "    acc_list.append(acc)\n",
        "  return acc_list,losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlM4jm8BOw2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "#test_classes=np.max(testframe['Label'])-np.min(testframe['Label'])\n",
        "test_classes=list(np.arange(np.min(testframe['Label']),np.max(testframe['Label']+1)))\n",
        "acc_list,losses=evaluate(net,test_classes,task_lr=1e-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw2vK__L-QE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_test_accuracy=(sum(acc_list)/len(acc_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ejdb6VNZdJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "average_test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}